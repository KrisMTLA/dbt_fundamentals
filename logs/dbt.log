2022-03-11 14:59:41.454172 (MainThread): Running with dbt=0.20.2
2022-03-11 14:59:42.325287 (MainThread): NumExpr defaulting to 8 threads.
2022-03-11 14:59:42.508742 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-11 14:59:42.511882 (MainThread): Tracking: tracking
2022-03-11 14:59:42.525733 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa733d89d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa71ccafa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa727b26d0>]}
2022-03-11 14:59:42.534746 (MainThread): Partial parsing not enabled
2022-03-11 14:59:42.544132 (MainThread): Parsing macros/etc.sql
2022-03-11 14:59:42.546790 (MainThread): Parsing macros/catalog.sql
2022-03-11 14:59:42.552169 (MainThread): Parsing macros/adapters.sql
2022-03-11 14:59:42.565177 (MainThread): Parsing macros/materializations/seed.sql
2022-03-11 14:59:42.566807 (MainThread): Parsing macros/materializations/view.sql
2022-03-11 14:59:42.568510 (MainThread): Parsing macros/materializations/table.sql
2022-03-11 14:59:42.574925 (MainThread): Parsing macros/materializations/copy.sql
2022-03-11 14:59:42.577686 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-11 14:59:42.585892 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-11 14:59:42.586912 (MainThread): Parsing macros/core.sql
2022-03-11 14:59:42.589315 (MainThread): Parsing macros/materializations/test.sql
2022-03-11 14:59:42.593859 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-11 14:59:42.600595 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-11 14:59:42.601648 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-11 14:59:42.613281 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-11 14:59:42.639321 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-11 14:59:42.654286 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-11 14:59:42.655389 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-11 14:59:42.660518 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-11 14:59:42.670565 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-11 14:59:42.675409 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-11 14:59:42.679707 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-11 14:59:42.682890 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-11 14:59:42.683400 (MainThread): Parsing macros/etc/query.sql
2022-03-11 14:59:42.683957 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-11 14:59:42.684910 (MainThread): Parsing macros/etc/datetime.sql
2022-03-11 14:59:42.690739 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-11 14:59:42.691904 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-11 14:59:42.692843 (MainThread): Parsing macros/adapters/common.sql
2022-03-11 14:59:42.726416 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-11 14:59:42.727439 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-11 14:59:42.728123 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-11 14:59:42.728909 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-11 14:59:42.841255 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-11 14:59:42.847332 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-11 14:59:42.877772 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '862ef0ce-3a10-463e-bb3d-27f1f66b9fc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa50468760>]}
2022-03-11 14:59:42.880833 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-11 14:59:42.881445 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '862ef0ce-3a10-463e-bb3d-27f1f66b9fc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa503f2940>]}
2022-03-11 14:59:42.881587 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-11 14:59:42.882344 (MainThread): 
2022-03-11 14:59:42.882521 (MainThread): Acquiring new bigquery connection "master".
2022-03-11 14:59:42.883109 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-11 14:59:42.883238 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-11 14:59:42.883550 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-11 14:59:43.834853 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-11 14:59:43.835615 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-11 14:59:43.836091 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-11 14:59:44.071061 (MainThread): 09:59:44 | Concurrency: 8 threads (target='dev')
2022-03-11 14:59:44.071223 (MainThread): 09:59:44 | 
2022-03-11 14:59:44.074377 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-11 14:59:44.074691 (Thread-1): 09:59:44 | 1 of 2 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-11 14:59:44.074964 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-11 14:59:44.075077 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-11 14:59:44.076397 (Thread-1): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 59039), raddr=('172.217.13.202', 443)>
2022-03-11 14:59:44.076656 (Thread-1): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 59040), raddr=('172.217.13.106', 443)>
2022-03-11 14:59:44.076740 (Thread-1): unclosed <ssl.SSLSocket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 59041), raddr=('172.217.13.106', 443)>
2022-03-11 14:59:44.078821 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-11 14:59:44.079284 (Thread-1): finished collecting timing info
2022-03-11 14:59:44.106019 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-11 14:59:44.106471 (Thread-1): Opening a new connection, currently in state closed
2022-03-11 14:59:44.106557 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-11 14:59:46.082009 (Thread-1): finished collecting timing info
2022-03-11 14:59:46.082771 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '862ef0ce-3a10-463e-bb3d-27f1f66b9fc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa7342fcd0>]}
2022-03-11 14:59:46.083845 (Thread-1): 09:59:46 | 1 of 2 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.01s]
2022-03-11 14:59:46.084069 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-11 14:59:46.085094 (Thread-3): Began running node model.my_new_project.my_second_dbt_model
2022-03-11 14:59:46.085474 (Thread-3): 09:59:46 | 2 of 2 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-11 14:59:46.085888 (Thread-3): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-11 14:59:46.086038 (Thread-3): Compiling model.my_new_project.my_second_dbt_model
2022-03-11 14:59:46.090157 (Thread-3): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-11 14:59:46.090844 (Thread-3): finished collecting timing info
2022-03-11 14:59:46.115247 (Thread-3): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-11 14:59:46.115753 (Thread-3): Opening a new connection, currently in state init
2022-03-11 14:59:46.115897 (Thread-3): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-11 14:59:46.987811 (Thread-3): finished collecting timing info
2022-03-11 14:59:46.988580 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '862ef0ce-3a10-463e-bb3d-27f1f66b9fc1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa400f5820>]}
2022-03-11 14:59:46.989099 (Thread-3): 09:59:46 | 2 of 2 OK created view model dbt_kris.my_second_dbt_model............ [OK in 0.90s]
2022-03-11 14:59:46.989291 (Thread-3): Finished running node model.my_new_project.my_second_dbt_model
2022-03-11 14:59:46.991247 (MainThread): Acquiring new bigquery connection "master".
2022-03-11 14:59:46.991698 (MainThread): 09:59:46 | 
2022-03-11 14:59:46.991867 (MainThread): 09:59:46 | Finished running 1 table model, 1 view model in 4.11s.
2022-03-11 14:59:46.992015 (MainThread): Connection 'master' was properly closed.
2022-03-11 14:59:46.992120 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-11 14:59:46.992216 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-11 14:59:47.000027 (MainThread): 
2022-03-11 14:59:47.000210 (MainThread): Completed successfully
2022-03-11 14:59:47.000345 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-03-11 14:59:47.000646 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa71ccafa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa72103cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa5043cbb0>]}
2022-03-11 14:59:47.000986 (MainThread): Flushing usage events
2022-03-14 15:16:24.321339 (MainThread): Running with dbt=0.20.2
2022-03-14 15:16:25.529737 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 15:16:25.793895 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 15:16:25.797358 (MainThread): Tracking: tracking
2022-03-14 15:16:25.822144 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6b06819d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c2872fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c337a700>]}
2022-03-14 15:16:25.831338 (MainThread): Partial parsing not enabled
2022-03-14 15:16:25.839873 (MainThread): Parsing macros/etc.sql
2022-03-14 15:16:25.842530 (MainThread): Parsing macros/catalog.sql
2022-03-14 15:16:25.847755 (MainThread): Parsing macros/adapters.sql
2022-03-14 15:16:25.860797 (MainThread): Parsing macros/materializations/seed.sql
2022-03-14 15:16:25.862441 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 15:16:25.864140 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 15:16:25.870563 (MainThread): Parsing macros/materializations/copy.sql
2022-03-14 15:16:25.873450 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 15:16:25.881701 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-14 15:16:25.882743 (MainThread): Parsing macros/core.sql
2022-03-14 15:16:25.885146 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 15:16:25.889687 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 15:16:25.896443 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 15:16:25.897485 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 15:16:25.909315 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 15:16:25.936103 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 15:16:25.951275 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 15:16:25.952383 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 15:16:25.957470 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 15:16:25.967702 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 15:16:25.972634 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 15:16:25.976960 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 15:16:25.980151 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 15:16:25.980664 (MainThread): Parsing macros/etc/query.sql
2022-03-14 15:16:25.981225 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 15:16:25.982271 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 15:16:25.988177 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 15:16:25.989345 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 15:16:25.990282 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 15:16:26.024421 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 15:16:26.025481 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 15:16:26.026160 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 15:16:26.026951 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 15:16:26.139016 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:16:26.145124 (MainThread): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:16:26.146623 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:16:26.177489 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '89fb3a19-af6e-4313-bd13-e565fdf00c96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c3cade20>]}
2022-03-14 15:16:26.180371 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 15:16:26.180799 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89fb3a19-af6e-4313-bd13-e565fdf00c96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c3cadc40>]}
2022-03-14 15:16:26.180918 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 15:16:26.181647 (MainThread): 
2022-03-14 15:16:26.181810 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:16:26.182389 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-14 15:16:26.182516 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 15:16:26.183299 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-14 15:16:27.784084 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-14 15:16:27.784832 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 15:16:27.785257 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:16:28.018711 (MainThread): 11:16:28 | Concurrency: 8 threads (target='dev')
2022-03-14 15:16:28.018930 (MainThread): 11:16:28 | 
2022-03-14 15:16:28.022712 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 15:16:28.022889 (Thread-2): Began running node model.my_new_project.dim_customer
2022-03-14 15:16:28.023179 (Thread-1): 11:16:28 | 1 of 3 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-14 15:16:28.023404 (Thread-2): 11:16:28 | 2 of 3 START view model dbt_kris.dim_customer........................ [RUN]
2022-03-14 15:16:28.023798 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:16:28.024136 (Thread-2): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:16:28.024330 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 15:16:28.024431 (Thread-2): Compiling model.my_new_project.dim_customer
2022-03-14 15:16:28.025996 (Thread-1): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61590), raddr=('172.217.13.138', 443)>
2022-03-14 15:16:28.027387 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:16:28.027632 (Thread-1): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61591), raddr=('172.217.13.138', 443)>
2022-03-14 15:16:28.027784 (Thread-1): unclosed <ssl.SSLSocket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61592), raddr=('172.217.13.138', 443)>
2022-03-14 15:16:28.030157 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:16:28.030327 (Thread-2): finished collecting timing info
2022-03-14 15:16:28.055691 (Thread-1): finished collecting timing info
2022-03-14 15:16:28.055944 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:16:28.066581 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 15:16:28.066831 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:16:28.067739 (Thread-2): Opening a new connection, currently in state init
2022-03-14 15:16:28.067892 (Thread-2): On model.my_new_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2022-03-14 15:16:28.283627 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:16:28.284437 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-14 15:16:28.321447 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('The project raw has not enabled BigQuery.')
2022-03-14 15:16:29.351781 (Thread-2): finished collecting timing info
2022-03-14 15:16:29.353641 (Thread-2): Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    yield
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 335, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 528, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1372, in result
    do_get_result()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    return retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1362, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 713, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py", line 135, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 The project raw has not enabled BigQuery.

(job ID: 1d1770c6-6bf3-4c73-afa6-ca92c7686175)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */
   2:
   3:
   4:  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
   5:  OPTIONS()
   6:  as with customers as (
   7:
   8:    select
   9:        id as customer_id,
  10:        first_name,
  11:        last_name
  12:
  13:    from raw.jaffle_shop.customers
  14:
  15:),
  16:
  17:orders as (
  18:
  19:    select
  20:        id as order_id,
  21:        user_id as customer_id,
  22:        order_date,
  23:        status
  24:
  25:    from raw.jaffle_shop.orders
  26:
  27:),
  28:
  29:customer_orders as (
  30:
  31:    select
  32:        customer_id,
  33:
  34:        min(order_date) as first_order_date,
  35:        max(order_date) as most_recent_order_date,
  36:        count(order_id) as number_of_orders
  37:
  38:    from orders
  39:
  40:    group by 1
  41:
  42:),
  43:
  44:
  45:final as (
  46:
  47:    select
  48:        customers.customer_id,
  49:        customers.first_name,
  50:        customers.last_name,
  51:        customer_orders.first_order_date,
  52:        customer_orders.most_recent_order_date,
  53:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  54:
  55:    from customers
  56:
  57:    left join customer_orders using (customer_id)
  58:
  59:)
  60:
  61:select * from final;
  62:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 337, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 145, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:16:29.365515 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89fb3a19-af6e-4313-bd13-e565fdf00c96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6b08130d0>]}
2022-03-14 15:16:29.366182 (Thread-2): 11:16:29 | 2 of 3 ERROR creating view model dbt_kris.dim_customer............... [ERROR in 1.34s]
2022-03-14 15:16:29.366388 (Thread-2): Finished running node model.my_new_project.dim_customer
2022-03-14 15:16:30.195284 (Thread-1): finished collecting timing info
2022-03-14 15:16:30.196034 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89fb3a19-af6e-4313-bd13-e565fdf00c96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c3d0efa0>]}
2022-03-14 15:16:30.196563 (Thread-1): 11:16:30 | 1 of 3 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.17s]
2022-03-14 15:16:30.196766 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 15:16:30.197899 (Thread-4): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 15:16:30.198260 (Thread-4): 11:16:30 | 3 of 3 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-14 15:16:30.198697 (Thread-4): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:16:30.198844 (Thread-4): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 15:16:30.203070 (Thread-4): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:16:30.203682 (Thread-4): finished collecting timing info
2022-03-14 15:16:30.207341 (Thread-4): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:16:30.207927 (Thread-4): Opening a new connection, currently in state init
2022-03-14 15:16:30.208085 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-14 15:16:30.907725 (Thread-4): finished collecting timing info
2022-03-14 15:16:30.908612 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89fb3a19-af6e-4313-bd13-e565fdf00c96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6b079fe50>]}
2022-03-14 15:16:30.909187 (Thread-4): 11:16:30 | 3 of 3 OK created view model dbt_kris.my_second_dbt_model............ [OK in 0.71s]
2022-03-14 15:16:30.909385 (Thread-4): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 15:16:30.911390 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:16:30.911939 (MainThread): 11:16:30 | 
2022-03-14 15:16:30.912123 (MainThread): 11:16:30 | Finished running 2 view models, 1 table model in 4.73s.
2022-03-14 15:16:30.912268 (MainThread): Connection 'master' was properly closed.
2022-03-14 15:16:30.912365 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 15:16:30.912457 (MainThread): Connection 'model.my_new_project.dim_customer' was properly closed.
2022-03-14 15:16:30.912545 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 15:16:30.914566 (MainThread): unclosed <ssl.SSLSocket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61595), raddr=('172.217.13.138', 443)>
2022-03-14 15:16:30.921953 (MainThread): 
2022-03-14 15:16:30.922218 (MainThread): Completed with 1 error and 0 warnings:
2022-03-14 15:16:30.922349 (MainThread): 
2022-03-14 15:16:30.922463 (MainThread): Database Error in model dim_customer (models/example/dim_customer.sql)
2022-03-14 15:16:30.922566 (MainThread):   The project raw has not enabled BigQuery.
2022-03-14 15:16:30.922662 (MainThread):   compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:16:30.922779 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2022-03-14 15:16:30.923087 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6b0702f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c3ca9b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c3ca1160>]}
2022-03-14 15:16:30.923361 (MainThread): Flushing usage events
2022-03-14 15:24:29.355224 (MainThread): Running with dbt=0.20.2
2022-03-14 15:24:30.540644 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 15:24:30.799897 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 15:24:30.803210 (MainThread): Tracking: tracking
2022-03-14 15:24:30.817463 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1c832fa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1dabfbd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1db2c7790>]}
2022-03-14 15:24:30.826446 (MainThread): Partial parsing not enabled
2022-03-14 15:24:30.834639 (MainThread): Parsing macros/etc.sql
2022-03-14 15:24:30.836958 (MainThread): Parsing macros/catalog.sql
2022-03-14 15:24:30.842361 (MainThread): Parsing macros/adapters.sql
2022-03-14 15:24:30.855145 (MainThread): Parsing macros/materializations/seed.sql
2022-03-14 15:24:30.856759 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 15:24:30.858442 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 15:24:30.864779 (MainThread): Parsing macros/materializations/copy.sql
2022-03-14 15:24:30.867507 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 15:24:30.875640 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-14 15:24:30.876655 (MainThread): Parsing macros/core.sql
2022-03-14 15:24:30.879054 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 15:24:30.883550 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 15:24:30.890407 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 15:24:30.891480 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 15:24:30.903062 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 15:24:30.929213 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 15:24:30.944148 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 15:24:30.945269 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 15:24:30.950338 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 15:24:30.960417 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 15:24:30.965271 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 15:24:30.969554 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 15:24:30.972727 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 15:24:30.973238 (MainThread): Parsing macros/etc/query.sql
2022-03-14 15:24:30.973804 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 15:24:30.974762 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 15:24:30.980560 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 15:24:30.981715 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 15:24:30.982667 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 15:24:31.016209 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 15:24:31.017236 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 15:24:31.017910 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 15:24:31.018691 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 15:24:31.130143 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:24:31.136218 (MainThread): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:24:31.137716 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:24:31.166848 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e673b5f0-3039-4d2b-a8d0-7fe85a3880fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1dbe55f70>]}
2022-03-14 15:24:31.169761 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 15:24:31.170285 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e673b5f0-3039-4d2b-a8d0-7fe85a3880fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1dbe55ac0>]}
2022-03-14 15:24:31.170407 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 15:24:31.171153 (MainThread): 
2022-03-14 15:24:31.171311 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:24:31.171902 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-14 15:24:31.172020 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 15:24:31.172765 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-14 15:24:32.308186 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-14 15:24:32.308469 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 15:24:32.308650 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:24:32.556022 (MainThread): 11:24:32 | Concurrency: 8 threads (target='dev')
2022-03-14 15:24:32.556413 (MainThread): 11:24:32 | 
2022-03-14 15:24:32.563163 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 15:24:32.563447 (Thread-2): Began running node model.my_new_project.dim_customer
2022-03-14 15:24:32.563755 (Thread-1): 11:24:32 | 1 of 3 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-14 15:24:32.563872 (Thread-2): 11:24:32 | 2 of 3 START view model dbt_kris.dim_customer........................ [RUN]
2022-03-14 15:24:32.564123 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:24:32.564288 (Thread-2): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:24:32.564553 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 15:24:32.564738 (Thread-2): Compiling model.my_new_project.dim_customer
2022-03-14 15:24:32.566847 (Thread-1): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61693), raddr=('172.217.13.170', 443)>
2022-03-14 15:24:32.568860 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:24:32.569200 (Thread-1): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61694), raddr=('172.217.13.138', 443)>
2022-03-14 15:24:32.569395 (Thread-1): unclosed <ssl.SSLSocket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61695), raddr=('172.217.13.138', 443)>
2022-03-14 15:24:32.571645 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:24:32.572263 (Thread-2): finished collecting timing info
2022-03-14 15:24:32.572452 (Thread-1): finished collecting timing info
2022-03-14 15:24:32.615544 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:24:32.616433 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 15:24:32.616675 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:24:32.617542 (Thread-2): Opening a new connection, currently in state init
2022-03-14 15:24:32.617670 (Thread-2): On model.my_new_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2022-03-14 15:24:32.824607 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:24:32.825396 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-14 15:24:32.957368 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('The project raw has not enabled BigQuery.')
2022-03-14 15:24:33.313781 (Thread-2): finished collecting timing info
2022-03-14 15:24:33.315655 (Thread-2): Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    yield
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 335, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 528, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1372, in result
    do_get_result()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    return retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1362, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 713, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py", line 135, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 The project raw has not enabled BigQuery.

(job ID: bfe37f00-a874-4108-a3a1-a5b863ae693d)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */
   2:
   3:
   4:  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
   5:  OPTIONS()
   6:  as with customers as (
   7:
   8:    select
   9:        id as customer_id,
  10:        first_name,
  11:        last_name
  12:
  13:    from raw.jaffle_shop.customers
  14:
  15:),
  16:
  17:orders as (
  18:
  19:    select
  20:        id as order_id,
  21:        user_id as customer_id,
  22:        order_date,
  23:        status
  24:
  25:    from raw.jaffle_shop.orders
  26:
  27:),
  28:
  29:customer_orders as (
  30:
  31:    select
  32:        customer_id,
  33:
  34:        min(order_date) as first_order_date,
  35:        max(order_date) as most_recent_order_date,
  36:        count(order_id) as number_of_orders
  37:
  38:    from orders
  39:
  40:    group by 1
  41:
  42:),
  43:
  44:
  45:final as (
  46:
  47:    select
  48:        customers.customer_id,
  49:        customers.first_name,
  50:        customers.last_name,
  51:        customer_orders.first_order_date,
  52:        customer_orders.most_recent_order_date,
  53:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  54:
  55:    from customers
  56:
  57:    left join customer_orders using (customer_id)
  58:
  59:)
  60:
  61:select * from final;
  62:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 337, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 145, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:24:33.329487 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e673b5f0-3039-4d2b-a8d0-7fe85a3880fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1b804a700>]}
2022-03-14 15:24:33.330220 (Thread-2): 11:24:33 | 2 of 3 ERROR creating view model dbt_kris.dim_customer............... [ERROR in 0.77s]
2022-03-14 15:24:33.330437 (Thread-2): Finished running node model.my_new_project.dim_customer
2022-03-14 15:24:34.858371 (Thread-1): finished collecting timing info
2022-03-14 15:24:34.859073 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e673b5f0-3039-4d2b-a8d0-7fe85a3880fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1c85c82b0>]}
2022-03-14 15:24:34.859586 (Thread-1): 11:24:34 | 1 of 3 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.29s]
2022-03-14 15:24:34.859780 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 15:24:34.860558 (Thread-4): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 15:24:34.861078 (Thread-4): 11:24:34 | 3 of 3 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-14 15:24:34.861642 (Thread-4): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:24:34.861831 (Thread-4): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 15:24:34.865895 (Thread-4): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:24:34.866524 (Thread-4): finished collecting timing info
2022-03-14 15:24:34.870153 (Thread-4): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:24:34.870697 (Thread-4): Opening a new connection, currently in state init
2022-03-14 15:24:34.870860 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-14 15:24:35.437714 (Thread-4): finished collecting timing info
2022-03-14 15:24:35.439054 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e673b5f0-3039-4d2b-a8d0-7fe85a3880fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1b8035f10>]}
2022-03-14 15:24:35.439848 (Thread-4): 11:24:35 | 3 of 3 OK created view model dbt_kris.my_second_dbt_model............ [OK in 0.58s]
2022-03-14 15:24:35.440102 (Thread-4): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 15:24:35.442635 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:24:35.443252 (MainThread): 11:24:35 | 
2022-03-14 15:24:35.443457 (MainThread): 11:24:35 | Finished running 2 view models, 1 table model in 4.27s.
2022-03-14 15:24:35.443617 (MainThread): Connection 'master' was properly closed.
2022-03-14 15:24:35.443720 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 15:24:35.443813 (MainThread): Connection 'model.my_new_project.dim_customer' was properly closed.
2022-03-14 15:24:35.443905 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 15:24:35.445980 (MainThread): unclosed <ssl.SSLSocket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61698), raddr=('172.217.13.138', 443)>
2022-03-14 15:24:35.452843 (MainThread): 
2022-03-14 15:24:35.453091 (MainThread): Completed with 1 error and 0 warnings:
2022-03-14 15:24:35.453239 (MainThread): 
2022-03-14 15:24:35.453377 (MainThread): Database Error in model dim_customer (models/example/dim_customer.sql)
2022-03-14 15:24:35.453500 (MainThread):   The project raw has not enabled BigQuery.
2022-03-14 15:24:35.453613 (MainThread):   compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:24:35.453761 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2022-03-14 15:24:35.454083 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1dbe74d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1dbe51e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1dbe27d90>]}
2022-03-14 15:24:35.454325 (MainThread): Flushing usage events
2022-03-14 15:26:21.180687 (MainThread): Running with dbt=0.20.2
2022-03-14 15:26:22.291981 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 15:26:22.554944 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 15:26:22.560514 (MainThread): Tracking: tracking
2022-03-14 15:26:22.576425 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9c09a79d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d22a3fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9d2da96d0>]}
2022-03-14 15:26:22.585360 (MainThread): Partial parsing not enabled
2022-03-14 15:26:22.593408 (MainThread): Parsing macros/etc.sql
2022-03-14 15:26:22.595570 (MainThread): Parsing macros/catalog.sql
2022-03-14 15:26:22.600899 (MainThread): Parsing macros/adapters.sql
2022-03-14 15:26:22.613580 (MainThread): Parsing macros/materializations/seed.sql
2022-03-14 15:26:22.615189 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 15:26:22.616862 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 15:26:22.623130 (MainThread): Parsing macros/materializations/copy.sql
2022-03-14 15:26:22.625841 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 15:26:22.633883 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-14 15:26:22.634888 (MainThread): Parsing macros/core.sql
2022-03-14 15:26:22.637236 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 15:26:22.641686 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 15:26:22.648278 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 15:26:22.649311 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 15:26:22.660676 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 15:26:22.686113 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 15:26:22.700706 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 15:26:22.701788 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 15:26:22.706772 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 15:26:22.716594 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 15:26:22.721327 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 15:26:22.725530 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 15:26:22.728639 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 15:26:22.729141 (MainThread): Parsing macros/etc/query.sql
2022-03-14 15:26:22.729689 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 15:26:22.730622 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 15:26:22.736325 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 15:26:22.737458 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 15:26:22.738382 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 15:26:22.771192 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 15:26:22.772188 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 15:26:22.772848 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 15:26:22.773620 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 15:26:22.884259 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:26:22.890270 (MainThread): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:26:22.892280 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:26:22.921322 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '11f296c6-937f-49c0-8d7d-78b5697888d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b09c87f0>]}
2022-03-14 15:26:22.924238 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 15:26:22.925006 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '11f296c6-937f-49c0-8d7d-78b5697888d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b09c8430>]}
2022-03-14 15:26:22.925149 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 15:26:22.925889 (MainThread): 
2022-03-14 15:26:22.926053 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:26:22.926656 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-14 15:26:22.926744 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 15:26:22.927348 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-14 15:26:23.930110 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-14 15:26:23.930892 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 15:26:23.931378 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:26:24.160443 (MainThread): 11:26:24 | Concurrency: 8 threads (target='dev')
2022-03-14 15:26:24.160811 (MainThread): 11:26:24 | 
2022-03-14 15:26:24.165856 (MainThread): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61712), raddr=('172.217.13.170', 443)>
2022-03-14 15:26:24.166148 (MainThread): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61713), raddr=('172.217.13.138', 443)>
2022-03-14 15:26:24.169368 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 15:26:24.169591 (Thread-2): Began running node model.my_new_project.dim_customer
2022-03-14 15:26:24.169912 (Thread-1): 11:26:24 | 1 of 3 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-14 15:26:24.170186 (Thread-2): 11:26:24 | 2 of 3 START table model dbt_kris.dim_customer....................... [RUN]
2022-03-14 15:26:24.170678 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:26:24.171064 (Thread-2): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:26:24.171241 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 15:26:24.171371 (Thread-2): Compiling model.my_new_project.dim_customer
2022-03-14 15:26:24.176167 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:26:24.178983 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:26:24.179354 (Thread-1): finished collecting timing info
2022-03-14 15:26:24.185657 (Thread-2): finished collecting timing info
2022-03-14 15:26:24.207857 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 15:26:24.214344 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:26:24.224610 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:26:24.225264 (Thread-2): Opening a new connection, currently in state init
2022-03-14 15:26:24.225351 (Thread-2): On model.my_new_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
  
  
  OPTIONS()
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2022-03-14 15:26:24.418424 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:26:24.419201 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-14 15:26:24.530253 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('The project raw has not enabled BigQuery.')
2022-03-14 15:26:25.420686 (Thread-2): finished collecting timing info
2022-03-14 15:26:25.422255 (Thread-2): Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    yield
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 335, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 528, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1372, in result
    do_get_result()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    return retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1362, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 713, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py", line 135, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 The project raw has not enabled BigQuery.

(job ID: 01eac515-3832-437d-957b-33f2cf8e234a)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */
   2:
   3:
   4:  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:with customers as (
  12:
  13:    select
  14:        id as customer_id,
  15:        first_name,
  16:        last_name
  17:
  18:    from raw.jaffle_shop.customers
  19:
  20:),
  21:
  22:orders as (
  23:
  24:    select
  25:        id as order_id,
  26:        user_id as customer_id,
  27:        order_date,
  28:        status
  29:
  30:    from raw.jaffle_shop.orders
  31:
  32:),
  33:
  34:customer_orders as (
  35:
  36:    select
  37:        customer_id,
  38:
  39:        min(order_date) as first_order_date,
  40:        max(order_date) as most_recent_order_date,
  41:        count(order_id) as number_of_orders
  42:
  43:    from orders
  44:
  45:    group by 1
  46:
  47:),
  48:
  49:
  50:final as (
  51:
  52:    select
  53:        customers.customer_id,
  54:        customers.first_name,
  55:        customers.last_name,
  56:        customer_orders.first_order_date,
  57:        customer_orders.most_recent_order_date,
  58:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  59:
  60:    from customers
  61:
  62:    left join customer_orders using (customer_id)
  63:
  64:)
  65:
  66:select * from final
  67:  );
  68:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 337, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 145, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:26:25.434126 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11f296c6-937f-49c0-8d7d-78b5697888d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b0a6b490>]}
2022-03-14 15:26:25.434888 (Thread-2): 11:26:25 | 2 of 3 ERROR creating table model dbt_kris.dim_customer.............. [ERROR in 1.26s]
2022-03-14 15:26:25.435104 (Thread-2): Finished running node model.my_new_project.dim_customer
2022-03-14 15:26:26.523725 (Thread-1): finished collecting timing info
2022-03-14 15:26:26.524462 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11f296c6-937f-49c0-8d7d-78b5697888d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b0a51700>]}
2022-03-14 15:26:26.524995 (Thread-1): 11:26:26 | 1 of 3 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.35s]
2022-03-14 15:26:26.525215 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 15:26:26.526184 (Thread-4): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 15:26:26.526690 (Thread-4): 11:26:26 | 3 of 3 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-14 15:26:26.527141 (Thread-4): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:26:26.527287 (Thread-4): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 15:26:26.530915 (Thread-4): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:26:26.531521 (Thread-4): finished collecting timing info
2022-03-14 15:26:26.555004 (Thread-4): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:26:26.555537 (Thread-4): Opening a new connection, currently in state init
2022-03-14 15:26:26.555678 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-14 15:26:27.102340 (Thread-4): finished collecting timing info
2022-03-14 15:26:27.103111 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11f296c6-937f-49c0-8d7d-78b5697888d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b0a45fd0>]}
2022-03-14 15:26:27.103682 (Thread-4): 11:26:27 | 3 of 3 OK created view model dbt_kris.my_second_dbt_model............ [OK in 0.58s]
2022-03-14 15:26:27.103893 (Thread-4): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 15:26:27.105675 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:26:27.106138 (MainThread): 11:26:27 | 
2022-03-14 15:26:27.106302 (MainThread): 11:26:27 | Finished running 2 table models, 1 view model in 4.18s.
2022-03-14 15:26:27.106435 (MainThread): Connection 'master' was properly closed.
2022-03-14 15:26:27.106530 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 15:26:27.106619 (MainThread): Connection 'model.my_new_project.dim_customer' was properly closed.
2022-03-14 15:26:27.106706 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 15:26:27.108346 (MainThread): unclosed <ssl.SSLSocket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61717), raddr=('172.217.13.138', 443)>
2022-03-14 15:26:27.114108 (MainThread): 
2022-03-14 15:26:27.114276 (MainThread): Completed with 1 error and 0 warnings:
2022-03-14 15:26:27.114390 (MainThread): 
2022-03-14 15:26:27.114504 (MainThread): Database Error in model dim_customer (models/example/dim_customer.sql)
2022-03-14 15:26:27.114613 (MainThread):   The project raw has not enabled BigQuery.
2022-03-14 15:26:27.114701 (MainThread):   compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:26:27.114805 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2022-03-14 15:26:27.115080 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b0a02f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9a00324f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9a0032730>]}
2022-03-14 15:26:27.115321 (MainThread): Flushing usage events
2022-03-14 15:36:01.157079 (MainThread): Running with dbt=0.20.2
2022-03-14 15:36:02.351066 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 15:36:02.603087 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 15:36:02.610177 (MainThread): Tracking: tracking
2022-03-14 15:36:02.629633 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cd049f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cc2392f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cc2ad0670>]}
2022-03-14 15:36:02.639204 (MainThread): Partial parsing not enabled
2022-03-14 15:36:02.647779 (MainThread): Parsing macros/etc.sql
2022-03-14 15:36:02.650168 (MainThread): Parsing macros/catalog.sql
2022-03-14 15:36:02.656004 (MainThread): Parsing macros/adapters.sql
2022-03-14 15:36:02.669540 (MainThread): Parsing macros/materializations/seed.sql
2022-03-14 15:36:02.671185 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 15:36:02.672906 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 15:36:02.679419 (MainThread): Parsing macros/materializations/copy.sql
2022-03-14 15:36:02.682206 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 15:36:02.690460 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-14 15:36:02.691486 (MainThread): Parsing macros/core.sql
2022-03-14 15:36:02.693917 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 15:36:02.698592 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 15:36:02.705582 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 15:36:02.706642 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 15:36:02.718483 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 15:36:02.746048 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 15:36:02.761611 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 15:36:02.762746 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 15:36:02.767936 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 15:36:02.778554 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 15:36:02.783520 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 15:36:02.787931 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 15:36:02.791177 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 15:36:02.791688 (MainThread): Parsing macros/etc/query.sql
2022-03-14 15:36:02.792245 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 15:36:02.793201 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 15:36:02.799250 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 15:36:02.800425 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 15:36:02.801385 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 15:36:02.837472 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 15:36:02.838502 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 15:36:02.839184 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 15:36:02.839971 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 15:36:02.952010 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:36:02.958079 (MainThread): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:36:02.960124 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:36:02.990663 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '76190825-217e-4070-83d0-7a4aec9ff2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8045e5e0>]}
2022-03-14 15:36:02.994193 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 15:36:02.994619 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '76190825-217e-4070-83d0-7a4aec9ff2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8045e100>]}
2022-03-14 15:36:02.994736 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 15:36:02.995460 (MainThread): 
2022-03-14 15:36:02.995620 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:36:02.996209 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-14 15:36:02.996340 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 15:36:02.996981 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-14 15:36:04.113281 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-14 15:36:04.114010 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 15:36:04.114439 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:36:04.350074 (MainThread): 11:36:04 | Concurrency: 8 threads (target='dev')
2022-03-14 15:36:04.350421 (MainThread): 11:36:04 | 
2022-03-14 15:36:04.354637 (MainThread): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61850), raddr=('172.217.13.170', 443)>
2022-03-14 15:36:04.355115 (MainThread): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61851), raddr=('172.217.13.202', 443)>
2022-03-14 15:36:04.358816 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 15:36:04.359110 (Thread-2): Began running node model.my_new_project.dim_customer
2022-03-14 15:36:04.359430 (Thread-1): 11:36:04 | 1 of 3 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-14 15:36:04.359718 (Thread-2): 11:36:04 | 2 of 3 START table model dbt_kris.dim_customer....................... [RUN]
2022-03-14 15:36:04.360248 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:36:04.360602 (Thread-2): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:36:04.360813 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 15:36:04.360941 (Thread-2): Compiling model.my_new_project.dim_customer
2022-03-14 15:36:04.366049 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:36:04.368924 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:36:04.369778 (Thread-2): finished collecting timing info
2022-03-14 15:36:04.369940 (Thread-1): finished collecting timing info
2022-03-14 15:36:04.409097 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 15:36:04.414643 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:36:04.419939 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:36:04.420848 (Thread-2): Opening a new connection, currently in state init
2022-03-14 15:36:04.420933 (Thread-2): On model.my_new_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
  
  
  OPTIONS()
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2022-03-14 15:36:04.623839 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:36:04.625168 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-14 15:36:04.713814 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('The project raw has not enabled BigQuery.')
2022-03-14 15:36:05.902231 (Thread-2): finished collecting timing info
2022-03-14 15:36:05.902747 (Thread-2): Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    yield
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 335, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 528, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1372, in result
    do_get_result()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    return retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1362, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 713, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py", line 135, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 The project raw has not enabled BigQuery.

(job ID: 2b6fd0be-a247-4cbc-988b-736ad56a9f08)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */
   2:
   3:
   4:  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:with customers as (
  12:
  13:    select
  14:        id as customer_id,
  15:        first_name,
  16:        last_name
  17:
  18:    from raw.jaffle_shop.customers
  19:
  20:),
  21:
  22:orders as (
  23:
  24:    select
  25:        id as order_id,
  26:        user_id as customer_id,
  27:        order_date,
  28:        status
  29:
  30:    from raw.jaffle_shop.orders
  31:
  32:),
  33:
  34:customer_orders as (
  35:
  36:    select
  37:        customer_id,
  38:
  39:        min(order_date) as first_order_date,
  40:        max(order_date) as most_recent_order_date,
  41:        count(order_id) as number_of_orders
  42:
  43:    from orders
  44:
  45:    group by 1
  46:
  47:),
  48:
  49:
  50:final as (
  51:
  52:    select
  53:        customers.customer_id,
  54:        customers.first_name,
  55:        customers.last_name,
  56:        customer_orders.first_order_date,
  57:        customer_orders.most_recent_order_date,
  58:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  59:
  60:    from customers
  61:
  62:    left join customer_orders using (customer_id)
  63:
  64:)
  65:
  66:select * from final
  67:  );
  68:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 337, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 145, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:36:05.910063 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76190825-217e-4070-83d0-7a4aec9ff2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cd0966e20>]}
2022-03-14 15:36:05.910548 (Thread-2): 11:36:05 | 2 of 3 ERROR creating table model dbt_kris.dim_customer.............. [ERROR in 1.55s]
2022-03-14 15:36:05.910702 (Thread-2): Finished running node model.my_new_project.dim_customer
2022-03-14 15:36:06.752160 (Thread-1): finished collecting timing info
2022-03-14 15:36:06.752827 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76190825-217e-4070-83d0-7a4aec9ff2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c780426a0>]}
2022-03-14 15:36:06.753346 (Thread-1): 11:36:06 | 1 of 3 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.39s]
2022-03-14 15:36:06.753550 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 15:36:06.754525 (Thread-4): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 15:36:06.754856 (Thread-4): 11:36:06 | 3 of 3 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-14 15:36:06.755271 (Thread-4): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:36:06.755417 (Thread-4): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 15:36:06.759301 (Thread-4): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:36:06.760057 (Thread-4): finished collecting timing info
2022-03-14 15:36:06.783106 (Thread-4): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:36:06.783637 (Thread-4): Opening a new connection, currently in state init
2022-03-14 15:36:06.783771 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-14 15:36:07.354150 (Thread-4): finished collecting timing info
2022-03-14 15:36:07.355577 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76190825-217e-4070-83d0-7a4aec9ff2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c78042790>]}
2022-03-14 15:36:07.356470 (Thread-4): 11:36:07 | 3 of 3 OK created view model dbt_kris.my_second_dbt_model............ [OK in 0.60s]
2022-03-14 15:36:07.356719 (Thread-4): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 15:36:07.358978 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:36:07.359625 (MainThread): 11:36:07 | 
2022-03-14 15:36:07.360141 (MainThread): 11:36:07 | Finished running 2 table models, 1 view model in 4.36s.
2022-03-14 15:36:07.360377 (MainThread): Connection 'master' was properly closed.
2022-03-14 15:36:07.360520 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 15:36:07.360646 (MainThread): Connection 'model.my_new_project.dim_customer' was properly closed.
2022-03-14 15:36:07.360767 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 15:36:07.362964 (MainThread): unclosed <ssl.SSLSocket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61855), raddr=('172.217.13.202', 443)>
2022-03-14 15:36:07.370346 (MainThread): 
2022-03-14 15:36:07.370619 (MainThread): Completed with 1 error and 0 warnings:
2022-03-14 15:36:07.370790 (MainThread): 
2022-03-14 15:36:07.370935 (MainThread): Database Error in model dim_customer (models/example/dim_customer.sql)
2022-03-14 15:36:07.371070 (MainThread):   The project raw has not enabled BigQuery.
2022-03-14 15:36:07.371187 (MainThread):   compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:36:07.371303 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2022-03-14 15:36:07.371586 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c80477040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c78033a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c78033be0>]}
2022-03-14 15:36:07.371833 (MainThread): Flushing usage events
2022-03-14 15:43:31.889871 (MainThread): Running with dbt=0.20.2
2022-03-14 15:43:33.066059 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 15:43:33.321104 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 15:43:33.324444 (MainThread): Tracking: tracking
2022-03-14 15:43:33.339366 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff61051f7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff609171f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6220216a0>]}
2022-03-14 15:43:33.348808 (MainThread): Partial parsing not enabled
2022-03-14 15:43:33.357079 (MainThread): Parsing macros/etc.sql
2022-03-14 15:43:33.359495 (MainThread): Parsing macros/catalog.sql
2022-03-14 15:43:33.364847 (MainThread): Parsing macros/adapters.sql
2022-03-14 15:43:33.377733 (MainThread): Parsing macros/materializations/seed.sql
2022-03-14 15:43:33.379359 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 15:43:33.381038 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 15:43:33.387366 (MainThread): Parsing macros/materializations/copy.sql
2022-03-14 15:43:33.390089 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 15:43:33.398157 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-14 15:43:33.399166 (MainThread): Parsing macros/core.sql
2022-03-14 15:43:33.401534 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 15:43:33.406024 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 15:43:33.412662 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 15:43:33.413691 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 15:43:33.425131 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 15:43:33.450937 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 15:43:33.465693 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 15:43:33.466783 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 15:43:33.471806 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 15:43:33.481773 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 15:43:33.486550 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 15:43:33.490789 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 15:43:33.493917 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 15:43:33.494420 (MainThread): Parsing macros/etc/query.sql
2022-03-14 15:43:33.494964 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 15:43:33.495899 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 15:43:33.501642 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 15:43:33.502789 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 15:43:33.503725 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 15:43:33.537128 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 15:43:33.538134 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 15:43:33.538797 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 15:43:33.539566 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 15:43:33.650778 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:43:33.656897 (MainThread): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:43:33.658899 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:43:33.688968 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'faee322f-2e2c-44b6-9e2e-f859c2de313b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff622b3b610>]}
2022-03-14 15:43:33.692232 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 15:43:33.692663 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'faee322f-2e2c-44b6-9e2e-f859c2de313b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff622b3b130>]}
2022-03-14 15:43:33.692798 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 15:43:33.693543 (MainThread): 
2022-03-14 15:43:33.693716 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:43:33.694325 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-14 15:43:33.694423 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 15:43:33.695194 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-14 15:43:34.773907 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-14 15:43:34.774660 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 15:43:34.775209 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:43:35.022784 (MainThread): 11:43:35 | Concurrency: 8 threads (target='dev')
2022-03-14 15:43:35.023222 (MainThread): 11:43:35 | 
2022-03-14 15:43:35.027317 (MainThread): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61941), raddr=('172.217.13.170', 443)>
2022-03-14 15:43:35.027648 (MainThread): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61942), raddr=('172.217.13.138', 443)>
2022-03-14 15:43:35.031568 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 15:43:35.031861 (Thread-2): Began running node model.my_new_project.dim_customer
2022-03-14 15:43:35.032191 (Thread-1): 11:43:35 | 1 of 3 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-14 15:43:35.032344 (Thread-2): 11:43:35 | 2 of 3 START table model dbt_kris.dim_customer....................... [RUN]
2022-03-14 15:43:35.032608 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:43:35.032789 (Thread-2): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:43:35.032902 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 15:43:35.032953 (Thread-2): Compiling model.my_new_project.dim_customer
2022-03-14 15:43:35.035181 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:43:35.037245 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:43:35.037960 (Thread-1): finished collecting timing info
2022-03-14 15:43:35.038111 (Thread-2): finished collecting timing info
2022-03-14 15:43:35.072072 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 15:43:35.078551 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:43:35.091119 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:43:35.091926 (Thread-2): Opening a new connection, currently in state init
2022-03-14 15:43:35.092009 (Thread-2): On model.my_new_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
  
  
  OPTIONS()
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;
  );
    
2022-03-14 15:43:35.286192 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:43:35.287268 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-14 15:43:35.492327 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Syntax error: Expected ")" but got ";" at [66:20]')
2022-03-14 15:43:36.624922 (Thread-2): finished collecting timing info
2022-03-14 15:43:36.626475 (Thread-2): Database Error in model dim_customer (models/example/dim_customer.sql)
  Syntax error: Expected ")" but got ";" at [66:20]
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    yield
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 335, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 528, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1372, in result
    do_get_result()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    return retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1362, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 713, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py", line 135, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Syntax error: Expected ")" but got ";" at [66:20]

(job ID: c4892897-d230-46a4-adb0-3e97eb1ab59f)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */
   2:
   3:
   4:  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    
  10:
  11:with customers as (
  12:
  13:    select
  14:        id as customer_id,
  15:        first_name,
  16:        last_name
  17:
  18:    from raw.jaffle_shop.customers
  19:
  20:),
  21:
  22:orders as (
  23:
  24:    select
  25:        id as order_id,
  26:        user_id as customer_id,
  27:        order_date,
  28:        status
  29:
  30:    from raw.jaffle_shop.orders
  31:
  32:),
  33:
  34:customer_orders as (
  35:
  36:    select
  37:        customer_id,
  38:
  39:        min(order_date) as first_order_date,
  40:        max(order_date) as most_recent_order_date,
  41:        count(order_id) as number_of_orders
  42:
  43:    from orders
  44:
  45:    group by 1
  46:
  47:),
  48:
  49:
  50:final as (
  51:
  52:    select
  53:        customers.customer_id,
  54:        customers.first_name,
  55:        customers.last_name,
  56:        customer_orders.first_order_date,
  57:        customer_orders.most_recent_order_date,
  58:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  59:
  60:    from customers
  61:
  62:    left join customer_orders using (customer_id)
  63:
  64:)
  65:
  66:select * from final;
  67:  );
  68:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 337, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 145, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_customer (models/example/dim_customer.sql)
  Syntax error: Expected ")" but got ";" at [66:20]
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:43:36.637583 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'faee322f-2e2c-44b6-9e2e-f859c2de313b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff622bf61c0>]}
2022-03-14 15:43:36.638283 (Thread-2): 11:43:36 | 2 of 3 ERROR creating table model dbt_kris.dim_customer.............. [ERROR in 1.60s]
2022-03-14 15:43:36.638501 (Thread-2): Finished running node model.my_new_project.dim_customer
2022-03-14 15:43:37.365201 (Thread-1): finished collecting timing info
2022-03-14 15:43:37.365932 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'faee322f-2e2c-44b6-9e2e-f859c2de313b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5f0042a00>]}
2022-03-14 15:43:37.366453 (Thread-1): 11:43:37 | 1 of 3 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.33s]
2022-03-14 15:43:37.366660 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 15:43:37.367798 (Thread-4): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 15:43:37.368118 (Thread-4): 11:43:37 | 3 of 3 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-14 15:43:37.368568 (Thread-4): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:43:37.368734 (Thread-4): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 15:43:37.373212 (Thread-4): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:43:37.373894 (Thread-4): finished collecting timing info
2022-03-14 15:43:37.398353 (Thread-4): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:43:37.398962 (Thread-4): Opening a new connection, currently in state init
2022-03-14 15:43:37.399112 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-14 15:43:38.200574 (Thread-4): finished collecting timing info
2022-03-14 15:43:38.201233 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'faee322f-2e2c-44b6-9e2e-f859c2de313b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff610624b80>]}
2022-03-14 15:43:38.201796 (Thread-4): 11:43:38 | 3 of 3 OK created view model dbt_kris.my_second_dbt_model............ [OK in 0.83s]
2022-03-14 15:43:38.202006 (Thread-4): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 15:43:38.203868 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:43:38.204411 (MainThread): 11:43:38 | 
2022-03-14 15:43:38.204606 (MainThread): 11:43:38 | Finished running 2 table models, 1 view model in 4.51s.
2022-03-14 15:43:38.204752 (MainThread): Connection 'master' was properly closed.
2022-03-14 15:43:38.204854 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 15:43:38.204952 (MainThread): Connection 'model.my_new_project.dim_customer' was properly closed.
2022-03-14 15:43:38.205046 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 15:43:38.207156 (MainThread): unclosed <ssl.SSLSocket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61946), raddr=('172.217.13.138', 443)>
2022-03-14 15:43:38.213456 (MainThread): 
2022-03-14 15:43:38.213629 (MainThread): Completed with 1 error and 0 warnings:
2022-03-14 15:43:38.213760 (MainThread): 
2022-03-14 15:43:38.213880 (MainThread): Database Error in model dim_customer (models/example/dim_customer.sql)
2022-03-14 15:43:38.213983 (MainThread):   Syntax error: Expected ")" but got ";" at [66:20]
2022-03-14 15:43:38.214076 (MainThread):   compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:43:38.214190 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2022-03-14 15:43:38.214480 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff622b4cca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5f00336d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5f0033580>]}
2022-03-14 15:43:38.214743 (MainThread): Flushing usage events
2022-03-14 15:46:08.310944 (MainThread): Running with dbt=0.20.2
2022-03-14 15:46:09.499272 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 15:46:09.741919 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 15:46:09.745094 (MainThread): Tracking: tracking
2022-03-14 15:46:09.761816 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb140385af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb15032bd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb162f68790>]}
2022-03-14 15:46:09.771116 (MainThread): Partial parsing not enabled
2022-03-14 15:46:09.778823 (MainThread): Parsing macros/etc.sql
2022-03-14 15:46:09.781019 (MainThread): Parsing macros/catalog.sql
2022-03-14 15:46:09.786394 (MainThread): Parsing macros/adapters.sql
2022-03-14 15:46:09.799203 (MainThread): Parsing macros/materializations/seed.sql
2022-03-14 15:46:09.800841 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 15:46:09.802526 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 15:46:09.808881 (MainThread): Parsing macros/materializations/copy.sql
2022-03-14 15:46:09.811608 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 15:46:09.819757 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-14 15:46:09.820765 (MainThread): Parsing macros/core.sql
2022-03-14 15:46:09.823141 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 15:46:09.827649 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 15:46:09.834328 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 15:46:09.835356 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 15:46:09.847050 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 15:46:09.873036 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 15:46:09.888154 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 15:46:09.889286 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 15:46:09.894393 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 15:46:09.904472 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 15:46:09.909314 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 15:46:09.913612 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 15:46:09.916786 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 15:46:09.917299 (MainThread): Parsing macros/etc/query.sql
2022-03-14 15:46:09.917860 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 15:46:09.918810 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 15:46:09.924615 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 15:46:09.925775 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 15:46:09.926730 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 15:46:09.962050 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 15:46:09.963160 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 15:46:09.963847 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 15:46:09.964639 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 15:46:10.076116 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:46:10.082150 (MainThread): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:46:10.083649 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:46:10.113699 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6149ba5a-2e04-4dcd-9edc-bdf8d1f5817e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb14065da90>]}
2022-03-14 15:46:10.116529 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 15:46:10.116994 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6149ba5a-2e04-4dcd-9edc-bdf8d1f5817e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb14065d6d0>]}
2022-03-14 15:46:10.117109 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 15:46:10.117809 (MainThread): 
2022-03-14 15:46:10.117964 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:46:10.118549 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-14 15:46:10.118624 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 15:46:10.119195 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-14 15:46:11.099489 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-14 15:46:11.100291 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 15:46:11.100720 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:46:11.352576 (MainThread): 11:46:11 | Concurrency: 8 threads (target='dev')
2022-03-14 15:46:11.352833 (MainThread): 11:46:11 | 
2022-03-14 15:46:11.357858 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 15:46:11.358144 (Thread-2): Began running node model.my_new_project.dim_customer
2022-03-14 15:46:11.358420 (Thread-1): 11:46:11 | 1 of 3 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-14 15:46:11.358646 (Thread-2): 11:46:11 | 2 of 3 START view model dbt_kris.dim_customer........................ [RUN]
2022-03-14 15:46:11.359071 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:46:11.359319 (Thread-2): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:46:11.359472 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 15:46:11.359553 (Thread-2): Compiling model.my_new_project.dim_customer
2022-03-14 15:46:11.361057 (Thread-1): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61965), raddr=('172.217.13.170', 443)>
2022-03-14 15:46:11.362589 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:46:11.362837 (Thread-1): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61967), raddr=('172.217.13.138', 443)>
2022-03-14 15:46:11.363018 (Thread-1): unclosed <ssl.SSLSocket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61968), raddr=('172.217.13.138', 443)>
2022-03-14 15:46:11.365742 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:46:11.366009 (Thread-2): finished collecting timing info
2022-03-14 15:46:11.379313 (Thread-1): finished collecting timing info
2022-03-14 15:46:11.393466 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:46:11.404534 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 15:46:11.404744 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:46:11.405547 (Thread-2): Opening a new connection, currently in state init
2022-03-14 15:46:11.405682 (Thread-2): On model.my_new_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2022-03-14 15:46:11.652950 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:46:11.653587 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-14 15:46:11.702924 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('The project raw has not enabled BigQuery.')
2022-03-14 15:46:12.916111 (Thread-2): finished collecting timing info
2022-03-14 15:46:12.917453 (Thread-2): Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    yield
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 335, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 528, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1372, in result
    do_get_result()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    return retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1362, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 713, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py", line 135, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 The project raw has not enabled BigQuery.

(job ID: 50a12c33-e427-4839-8c26-9af867435314)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */
   2:
   3:
   4:  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
   5:  OPTIONS()
   6:  as with customers as (
   7:
   8:    select
   9:        id as customer_id,
  10:        first_name,
  11:        last_name
  12:
  13:    from raw.jaffle_shop.customers
  14:
  15:),
  16:
  17:orders as (
  18:
  19:    select
  20:        id as order_id,
  21:        user_id as customer_id,
  22:        order_date,
  23:        status
  24:
  25:    from raw.jaffle_shop.orders
  26:
  27:),
  28:
  29:customer_orders as (
  30:
  31:    select
  32:        customer_id,
  33:
  34:        min(order_date) as first_order_date,
  35:        max(order_date) as most_recent_order_date,
  36:        count(order_id) as number_of_orders
  37:
  38:    from orders
  39:
  40:    group by 1
  41:
  42:),
  43:
  44:
  45:final as (
  46:
  47:    select
  48:        customers.customer_id,
  49:        customers.first_name,
  50:        customers.last_name,
  51:        customer_orders.first_order_date,
  52:        customer_orders.most_recent_order_date,
  53:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  54:
  55:    from customers
  56:
  57:    left join customer_orders using (customer_id)
  58:
  59:)
  60:
  61:select * from final;
  62:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 337, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 145, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:46:12.927654 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6149ba5a-2e04-4dcd-9edc-bdf8d1f5817e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb163b2acd0>]}
2022-03-14 15:46:12.928337 (Thread-2): 11:46:12 | 2 of 3 ERROR creating view model dbt_kris.dim_customer............... [ERROR in 1.57s]
2022-03-14 15:46:12.928549 (Thread-2): Finished running node model.my_new_project.dim_customer
2022-03-14 15:46:13.844651 (Thread-1): finished collecting timing info
2022-03-14 15:46:13.845291 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6149ba5a-2e04-4dcd-9edc-bdf8d1f5817e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb163b61250>]}
2022-03-14 15:46:13.845778 (Thread-1): 11:46:13 | 1 of 3 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.49s]
2022-03-14 15:46:13.845967 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 15:46:13.847034 (Thread-4): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 15:46:13.847421 (Thread-4): 11:46:13 | 3 of 3 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-14 15:46:13.847869 (Thread-4): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:46:13.848021 (Thread-4): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 15:46:13.851677 (Thread-4): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:46:13.852249 (Thread-4): finished collecting timing info
2022-03-14 15:46:13.855868 (Thread-4): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:46:13.856340 (Thread-4): Opening a new connection, currently in state init
2022-03-14 15:46:13.856521 (Thread-4): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-14 15:46:14.603438 (Thread-4): finished collecting timing info
2022-03-14 15:46:14.604529 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6149ba5a-2e04-4dcd-9edc-bdf8d1f5817e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb1406eedf0>]}
2022-03-14 15:46:14.605338 (Thread-4): 11:46:14 | 3 of 3 OK created view model dbt_kris.my_second_dbt_model............ [OK in 0.76s]
2022-03-14 15:46:14.605676 (Thread-4): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 15:46:14.607728 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:46:14.608218 (MainThread): 11:46:14 | 
2022-03-14 15:46:14.608394 (MainThread): 11:46:14 | Finished running 2 view models, 1 table model in 4.49s.
2022-03-14 15:46:14.608543 (MainThread): Connection 'master' was properly closed.
2022-03-14 15:46:14.608648 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 15:46:14.608744 (MainThread): Connection 'model.my_new_project.dim_customer' was properly closed.
2022-03-14 15:46:14.608837 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 15:46:14.610826 (MainThread): unclosed <ssl.SSLSocket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 61971), raddr=('172.217.13.138', 443)>
2022-03-14 15:46:14.617292 (MainThread): 
2022-03-14 15:46:14.617594 (MainThread): Completed with 1 error and 0 warnings:
2022-03-14 15:46:14.617761 (MainThread): 
2022-03-14 15:46:14.617911 (MainThread): Database Error in model dim_customer (models/example/dim_customer.sql)
2022-03-14 15:46:14.618044 (MainThread):   The project raw has not enabled BigQuery.
2022-03-14 15:46:14.618159 (MainThread):   compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:46:14.618307 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2022-03-14 15:46:14.618664 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb14067cd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb140659940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb140659ee0>]}
2022-03-14 15:46:14.618977 (MainThread): Flushing usage events
2022-03-14 15:49:14.424329 (MainThread): Running with dbt=0.20.2
2022-03-14 15:49:15.638936 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 15:49:15.891833 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 15:49:15.895097 (MainThread): Tracking: tracking
2022-03-14 15:49:15.911695 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2c86a99d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2da9aaf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2db0aa670>]}
2022-03-14 15:49:15.921254 (MainThread): Partial parsing not enabled
2022-03-14 15:49:15.929865 (MainThread): Parsing macros/etc.sql
2022-03-14 15:49:15.932256 (MainThread): Parsing macros/catalog.sql
2022-03-14 15:49:15.937514 (MainThread): Parsing macros/adapters.sql
2022-03-14 15:49:15.950324 (MainThread): Parsing macros/materializations/seed.sql
2022-03-14 15:49:15.951984 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 15:49:15.953690 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 15:49:15.960072 (MainThread): Parsing macros/materializations/copy.sql
2022-03-14 15:49:15.962818 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 15:49:15.970945 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-14 15:49:15.971951 (MainThread): Parsing macros/core.sql
2022-03-14 15:49:15.974339 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 15:49:15.978852 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 15:49:15.985454 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 15:49:15.986480 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 15:49:15.997964 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 15:49:16.023426 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 15:49:16.038114 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 15:49:16.039207 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 15:49:16.044235 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 15:49:16.054103 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 15:49:16.058884 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 15:49:16.063100 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 15:49:16.066230 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 15:49:16.066737 (MainThread): Parsing macros/etc/query.sql
2022-03-14 15:49:16.067293 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 15:49:16.068241 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 15:49:16.073989 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 15:49:16.075139 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 15:49:16.076075 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 15:49:16.108964 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 15:49:16.109968 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 15:49:16.110636 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 15:49:16.111409 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 15:49:16.222655 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:49:16.228619 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_test".
2022-03-14 15:49:16.230543 (MainThread): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:49:16.232015 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:49:16.262691 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6b9ec15d-c01e-4b50-aba2-c9e418282d03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2c8750610>]}
2022-03-14 15:49:16.265761 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 15:49:16.266212 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6b9ec15d-c01e-4b50-aba2-c9e418282d03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2c8750610>]}
2022-03-14 15:49:16.266356 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 15:49:16.267156 (MainThread): 
2022-03-14 15:49:16.267327 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:49:16.267965 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-14 15:49:16.268060 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 15:49:16.268878 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-14 15:49:17.326607 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-14 15:49:17.327134 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 15:49:17.327487 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:49:17.566190 (MainThread): 11:49:17 | Concurrency: 8 threads (target='dev')
2022-03-14 15:49:17.566529 (MainThread): 11:49:17 | 
2022-03-14 15:49:17.570757 (MainThread): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62019), raddr=('172.217.13.202', 443)>
2022-03-14 15:49:17.571116 (MainThread): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62020), raddr=('172.217.13.202', 443)>
2022-03-14 15:49:17.574563 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 15:49:17.574847 (Thread-2): Began running node model.my_new_project.dim_customer
2022-03-14 15:49:17.574990 (Thread-3): Began running node model.my_new_project.my_test
2022-03-14 15:49:17.575275 (Thread-1): 11:49:17 | 1 of 4 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-14 15:49:17.575563 (Thread-2): 11:49:17 | 2 of 4 START view model dbt_kris.dim_customer........................ [RUN]
2022-03-14 15:49:17.575800 (Thread-3): 11:49:17 | 3 of 4 START table model dbt_kris.my_test............................ [RUN]
2022-03-14 15:49:17.576441 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:49:17.576910 (Thread-2): Acquiring new bigquery connection "model.my_new_project.dim_customer".
2022-03-14 15:49:17.577200 (Thread-3): Acquiring new bigquery connection "model.my_new_project.my_test".
2022-03-14 15:49:17.577419 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 15:49:17.577537 (Thread-2): Compiling model.my_new_project.dim_customer
2022-03-14 15:49:17.577642 (Thread-3): Compiling model.my_new_project.my_test
2022-03-14 15:49:17.582392 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:49:17.583828 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:49:17.586396 (Thread-3): Writing injected SQL for node "model.my_new_project.my_test"
2022-03-14 15:49:17.587274 (Thread-3): finished collecting timing info
2022-03-14 15:49:17.587504 (Thread-1): finished collecting timing info
2022-03-14 15:49:17.598805 (Thread-2): finished collecting timing info
2022-03-14 15:49:17.631235 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 15:49:17.642574 (Thread-3): Writing runtime SQL for node "model.my_new_project.my_test"
2022-03-14 15:49:17.649003 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:49:17.649885 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer"
2022-03-14 15:49:17.650849 (Thread-2): Opening a new connection, currently in state init
2022-03-14 15:49:17.650935 (Thread-3): Opening a new connection, currently in state init
2022-03-14 15:49:17.650997 (Thread-2): On model.my_new_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2022-03-14 15:49:17.651063 (Thread-3): On model.my_new_project.my_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_test"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_test`
  
  
  OPTIONS()
  as (
    

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
  );
    
2022-03-14 15:49:17.845990 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:49:17.846897 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-14 15:49:17.980033 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('The project raw has not enabled BigQuery.')
2022-03-14 15:49:19.178467 (Thread-2): finished collecting timing info
2022-03-14 15:49:19.179913 (Thread-2): Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    yield
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 335, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 528, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1372, in result
    do_get_result()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    return retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1362, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 713, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py", line 135, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 The project raw has not enabled BigQuery.

(job ID: 7db3cb8b-deb4-4437-933f-cc6fe5eeccf1)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer"} */
   2:
   3:
   4:  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer`
   5:  OPTIONS()
   6:  as with customers as (
   7:
   8:    select
   9:        id as customer_id,
  10:        first_name,
  11:        last_name
  12:
  13:    from raw.jaffle_shop.customers
  14:
  15:),
  16:
  17:orders as (
  18:
  19:    select
  20:        id as order_id,
  21:        user_id as customer_id,
  22:        order_date,
  23:        status
  24:
  25:    from raw.jaffle_shop.orders
  26:
  27:),
  28:
  29:customer_orders as (
  30:
  31:    select
  32:        customer_id,
  33:
  34:        min(order_date) as first_order_date,
  35:        max(order_date) as most_recent_order_date,
  36:        count(order_id) as number_of_orders
  37:
  38:    from orders
  39:
  40:    group by 1
  41:
  42:),
  43:
  44:
  45:final as (
  46:
  47:    select
  48:        customers.customer_id,
  49:        customers.first_name,
  50:        customers.last_name,
  51:        customer_orders.first_order_date,
  52:        customer_orders.most_recent_order_date,
  53:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  54:
  55:    from customers
  56:
  57:    left join customer_orders using (customer_id)
  58:
  59:)
  60:
  61:select * from final;
  62:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 337, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 145, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_customer (models/example/dim_customer.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:49:19.191197 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b9ec15d-c01e-4b50-aba2-c9e418282d03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b8293ee0>]}
2022-03-14 15:49:19.191939 (Thread-2): 11:49:19 | 2 of 4 ERROR creating view model dbt_kris.dim_customer............... [ERROR in 1.61s]
2022-03-14 15:49:19.192161 (Thread-2): Finished running node model.my_new_project.dim_customer
2022-03-14 15:49:19.764038 (Thread-3): finished collecting timing info
2022-03-14 15:49:19.764681 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b9ec15d-c01e-4b50-aba2-c9e418282d03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2c87d6a90>]}
2022-03-14 15:49:19.765123 (Thread-3): 11:49:19 | 3 of 4 OK created table model dbt_kris.my_test....................... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.19s]
2022-03-14 15:49:19.765287 (Thread-3): Finished running node model.my_new_project.my_test
2022-03-14 15:49:20.458647 (Thread-1): finished collecting timing info
2022-03-14 15:49:20.459923 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b9ec15d-c01e-4b50-aba2-c9e418282d03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b82d6910>]}
2022-03-14 15:49:20.460911 (Thread-1): 11:49:20 | 1 of 4 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.88s]
2022-03-14 15:49:20.461351 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 15:49:20.462763 (Thread-5): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 15:49:20.463211 (Thread-5): 11:49:20 | 4 of 4 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-14 15:49:20.463840 (Thread-5): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:49:20.464046 (Thread-5): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 15:49:20.468620 (Thread-5): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:49:20.469535 (Thread-5): finished collecting timing info
2022-03-14 15:49:20.473941 (Thread-5): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:49:20.474607 (Thread-5): Opening a new connection, currently in state init
2022-03-14 15:49:20.474784 (Thread-5): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-14 15:49:21.240894 (Thread-5): finished collecting timing info
2022-03-14 15:49:21.241660 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b9ec15d-c01e-4b50-aba2-c9e418282d03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd298042610>]}
2022-03-14 15:49:21.242220 (Thread-5): 11:49:21 | 4 of 4 OK created view model dbt_kris.my_second_dbt_model............ [OK in 0.78s]
2022-03-14 15:49:21.242414 (Thread-5): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 15:49:21.244250 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:49:21.244788 (MainThread): 11:49:21 | 
2022-03-14 15:49:21.244976 (MainThread): 11:49:21 | Finished running 2 view models, 2 table models in 4.98s.
2022-03-14 15:49:21.245125 (MainThread): Connection 'master' was properly closed.
2022-03-14 15:49:21.245229 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 15:49:21.245324 (MainThread): Connection 'model.my_new_project.dim_customer' was properly closed.
2022-03-14 15:49:21.245416 (MainThread): Connection 'model.my_new_project.my_test' was properly closed.
2022-03-14 15:49:21.245509 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 15:49:21.248849 (MainThread): unclosed <ssl.SSLSocket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62023), raddr=('172.217.13.202', 443)>
2022-03-14 15:49:21.249187 (MainThread): unclosed <ssl.SSLSocket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62024), raddr=('172.217.13.202', 443)>
2022-03-14 15:49:21.249413 (MainThread): unclosed <ssl.SSLSocket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62027), raddr=('172.217.13.202', 443)>
2022-03-14 15:49:21.256413 (MainThread): 
2022-03-14 15:49:21.256657 (MainThread): Completed with 1 error and 0 warnings:
2022-03-14 15:49:21.256783 (MainThread): 
2022-03-14 15:49:21.256900 (MainThread): Database Error in model dim_customer (models/example/dim_customer.sql)
2022-03-14 15:49:21.257004 (MainThread):   The project raw has not enabled BigQuery.
2022-03-14 15:49:21.257096 (MainThread):   compiled SQL at target/run/my_new_project/models/example/dim_customer.sql
2022-03-14 15:49:21.257210 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2022-03-14 15:49:21.257495 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2c8770c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd298033eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd298033b80>]}
2022-03-14 15:49:21.257732 (MainThread): Flushing usage events
2022-03-14 15:50:37.658110 (MainThread): Running with dbt=0.20.2
2022-03-14 15:50:38.678323 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 15:50:38.919178 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 15:50:38.922528 (MainThread): Tracking: tracking
2022-03-14 15:50:38.935693 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced8630a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fceca332cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fceb81a2730>]}
2022-03-14 15:50:38.944196 (MainThread): Partial parsing not enabled
2022-03-14 15:50:38.952092 (MainThread): Parsing macros/etc.sql
2022-03-14 15:50:38.954259 (MainThread): Parsing macros/catalog.sql
2022-03-14 15:50:38.959612 (MainThread): Parsing macros/adapters.sql
2022-03-14 15:50:38.972575 (MainThread): Parsing macros/materializations/seed.sql
2022-03-14 15:50:38.974186 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 15:50:38.975880 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 15:50:38.982240 (MainThread): Parsing macros/materializations/copy.sql
2022-03-14 15:50:38.984973 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 15:50:38.993129 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-14 15:50:38.994139 (MainThread): Parsing macros/core.sql
2022-03-14 15:50:38.996518 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 15:50:39.001016 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 15:50:39.007679 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 15:50:39.008705 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 15:50:39.020212 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 15:50:39.046130 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 15:50:39.060999 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 15:50:39.062098 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 15:50:39.067172 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 15:50:39.077265 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 15:50:39.082083 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 15:50:39.086389 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 15:50:39.089571 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 15:50:39.090082 (MainThread): Parsing macros/etc/query.sql
2022-03-14 15:50:39.090638 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 15:50:39.091593 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 15:50:39.097404 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 15:50:39.098571 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 15:50:39.099707 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 15:50:39.133626 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 15:50:39.134687 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 15:50:39.135379 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 15:50:39.136251 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 15:50:39.247757 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:50:39.253814 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_test".
2022-03-14 15:50:39.255740 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:50:39.257667 (MainThread): Acquiring new bigquery connection "model.my_new_project.dim_customer_test".
2022-03-14 15:50:39.286187 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '99dc5ac7-c30c-4912-8701-4275eb8f82bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcecb99fc70>]}
2022-03-14 15:50:39.289018 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 15:50:39.289265 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '99dc5ac7-c30c-4912-8701-4275eb8f82bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcecb99fc70>]}
2022-03-14 15:50:39.289384 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 15:50:39.290149 (MainThread): 
2022-03-14 15:50:39.290317 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:50:39.290956 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-14 15:50:39.291094 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 15:50:39.291626 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-14 15:50:40.281581 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-14 15:50:40.282337 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 15:50:40.282917 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:50:40.575758 (MainThread): 11:50:40 | Concurrency: 8 threads (target='dev')
2022-03-14 15:50:40.576099 (MainThread): 11:50:40 | 
2022-03-14 15:50:40.579499 (MainThread): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62040), raddr=('172.217.13.202', 443)>
2022-03-14 15:50:40.579797 (MainThread): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62041), raddr=('172.217.13.202', 443)>
2022-03-14 15:50:40.583365 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 15:50:40.583620 (Thread-2): Began running node model.my_new_project.dim_customer_test
2022-03-14 15:50:40.583810 (Thread-3): Began running node model.my_new_project.my_test
2022-03-14 15:50:40.584096 (Thread-1): 11:50:40 | 1 of 4 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-14 15:50:40.584311 (Thread-2): 11:50:40 | 2 of 4 START view model dbt_kris.dim_customer_test................... [RUN]
2022-03-14 15:50:40.584499 (Thread-3): 11:50:40 | 3 of 4 START table model dbt_kris.my_test............................ [RUN]
2022-03-14 15:50:40.585072 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:50:40.585405 (Thread-2): Acquiring new bigquery connection "model.my_new_project.dim_customer_test".
2022-03-14 15:50:40.585803 (Thread-3): Acquiring new bigquery connection "model.my_new_project.my_test".
2022-03-14 15:50:40.586030 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 15:50:40.586152 (Thread-2): Compiling model.my_new_project.dim_customer_test
2022-03-14 15:50:40.586244 (Thread-3): Compiling model.my_new_project.my_test
2022-03-14 15:50:40.590055 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:50:40.590724 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 15:50:40.591865 (Thread-3): Writing injected SQL for node "model.my_new_project.my_test"
2022-03-14 15:50:40.592553 (Thread-1): finished collecting timing info
2022-03-14 15:50:40.592749 (Thread-2): finished collecting timing info
2022-03-14 15:50:40.592858 (Thread-3): finished collecting timing info
2022-03-14 15:50:40.631947 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 15:50:40.633506 (Thread-3): Opening a new connection, currently in state init
2022-03-14 15:50:40.639429 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 15:50:40.639607 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:50:40.639682 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:50:40.641061 (Thread-2): Opening a new connection, currently in state init
2022-03-14 15:50:40.641172 (Thread-2): On model.my_new_project.dim_customer_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer_test"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer_test`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2022-03-14 15:50:40.859748 (Thread-3): Writing runtime SQL for node "model.my_new_project.my_test"
2022-03-14 15:50:40.860809 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:50:40.861419 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-14 15:50:40.861566 (Thread-3): On model.my_new_project.my_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_test"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_test`
  
  
  OPTIONS()
  as (
    

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
  );
    
2022-03-14 15:50:40.942195 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('The project raw has not enabled BigQuery.')
2022-03-14 15:50:41.747767 (Thread-2): finished collecting timing info
2022-03-14 15:50:41.749246 (Thread-2): Database Error in model dim_customer_test (models/example/dim_customer_test.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer_test.sql
Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    yield
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 335, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 528, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1372, in result
    do_get_result()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    return retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1362, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 713, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py", line 135, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 The project raw has not enabled BigQuery.

(job ID: 3c2b14d8-7f55-48a0-b34c-a3f36a57804f)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer_test"} */
   2:
   3:
   4:  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer_test`
   5:  OPTIONS()
   6:  as with customers as (
   7:
   8:    select
   9:        id as customer_id,
  10:        first_name,
  11:        last_name
  12:
  13:    from raw.jaffle_shop.customers
  14:
  15:),
  16:
  17:orders as (
  18:
  19:    select
  20:        id as order_id,
  21:        user_id as customer_id,
  22:        order_date,
  23:        status
  24:
  25:    from raw.jaffle_shop.orders
  26:
  27:),
  28:
  29:customer_orders as (
  30:
  31:    select
  32:        customer_id,
  33:
  34:        min(order_date) as first_order_date,
  35:        max(order_date) as most_recent_order_date,
  36:        count(order_id) as number_of_orders
  37:
  38:    from orders
  39:
  40:    group by 1
  41:
  42:),
  43:
  44:
  45:final as (
  46:
  47:    select
  48:        customers.customer_id,
  49:        customers.first_name,
  50:        customers.last_name,
  51:        customer_orders.first_order_date,
  52:        customer_orders.most_recent_order_date,
  53:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  54:
  55:    from customers
  56:
  57:    left join customer_orders using (customer_id)
  58:
  59:)
  60:
  61:select * from final;
  62:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 337, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 145, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_customer_test (models/example/dim_customer_test.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer_test.sql
2022-03-14 15:50:41.760210 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99dc5ac7-c30c-4912-8701-4275eb8f82bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fceb8232c10>]}
2022-03-14 15:50:41.760963 (Thread-2): 11:50:41 | 2 of 4 ERROR creating view model dbt_kris.dim_customer_test.......... [ERROR in 1.17s]
2022-03-14 15:50:41.761191 (Thread-2): Finished running node model.my_new_project.dim_customer_test
2022-03-14 15:50:42.830107 (Thread-1): finished collecting timing info
2022-03-14 15:50:42.830837 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99dc5ac7-c30c-4912-8701-4275eb8f82bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced86d2d00>]}
2022-03-14 15:50:42.831361 (Thread-1): 11:50:42 | 1 of 4 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.25s]
2022-03-14 15:50:42.831553 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 15:50:42.832139 (Thread-5): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 15:50:42.832533 (Thread-5): 11:50:42 | 4 of 4 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-14 15:50:42.832978 (Thread-5): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:50:42.833132 (Thread-5): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 15:50:42.837520 (Thread-5): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:50:42.838185 (Thread-5): finished collecting timing info
2022-03-14 15:50:42.841777 (Thread-5): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:50:42.842487 (Thread-5): Opening a new connection, currently in state init
2022-03-14 15:50:42.842659 (Thread-5): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-14 15:50:42.995030 (Thread-3): finished collecting timing info
2022-03-14 15:50:42.996464 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99dc5ac7-c30c-4912-8701-4275eb8f82bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced8698c70>]}
2022-03-14 15:50:42.997326 (Thread-3): 11:50:42 | 3 of 4 OK created table model dbt_kris.my_test....................... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.41s]
2022-03-14 15:50:42.997602 (Thread-3): Finished running node model.my_new_project.my_test
2022-03-14 15:50:43.713738 (Thread-5): finished collecting timing info
2022-03-14 15:50:43.715302 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99dc5ac7-c30c-4912-8701-4275eb8f82bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced8a3cd00>]}
2022-03-14 15:50:43.716230 (Thread-5): 11:50:43 | 4 of 4 OK created view model dbt_kris.my_second_dbt_model............ [OK in 0.88s]
2022-03-14 15:50:43.716542 (Thread-5): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 15:50:43.719469 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:50:43.720157 (MainThread): 11:50:43 | 
2022-03-14 15:50:43.720396 (MainThread): 11:50:43 | Finished running 2 view models, 2 table models in 4.43s.
2022-03-14 15:50:43.720581 (MainThread): Connection 'master' was properly closed.
2022-03-14 15:50:43.720711 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 15:50:43.720830 (MainThread): Connection 'model.my_new_project.dim_customer_test' was properly closed.
2022-03-14 15:50:43.720943 (MainThread): Connection 'model.my_new_project.my_test' was properly closed.
2022-03-14 15:50:43.721054 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 15:50:43.724707 (MainThread): unclosed <ssl.SSLSocket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62044), raddr=('172.217.13.202', 443)>
2022-03-14 15:50:43.725031 (MainThread): unclosed <ssl.SSLSocket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62045), raddr=('172.217.13.202', 443)>
2022-03-14 15:50:43.725213 (MainThread): unclosed <ssl.SSLSocket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62043), raddr=('172.217.13.202', 443)>
2022-03-14 15:50:43.725404 (MainThread): unclosed <ssl.SSLSocket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62046), raddr=('172.217.13.202', 443)>
2022-03-14 15:50:43.732797 (MainThread): 
2022-03-14 15:50:43.732984 (MainThread): Completed with 1 error and 0 warnings:
2022-03-14 15:50:43.733103 (MainThread): 
2022-03-14 15:50:43.733217 (MainThread): Database Error in model dim_customer_test (models/example/dim_customer_test.sql)
2022-03-14 15:50:43.733319 (MainThread):   The project raw has not enabled BigQuery.
2022-03-14 15:50:43.733410 (MainThread):   compiled SQL at target/run/my_new_project/models/example/dim_customer_test.sql
2022-03-14 15:50:43.733521 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2022-03-14 15:50:43.733803 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec80f5f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced8689cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced8689940>]}
2022-03-14 15:50:43.734043 (MainThread): Flushing usage events
2022-03-14 15:56:40.867990 (MainThread): Running with dbt=0.20.2
2022-03-14 15:56:42.043544 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 15:56:42.288309 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 15:56:42.291525 (MainThread): Tracking: tracking
2022-03-14 15:56:42.307721 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef026c940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf02bb9f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf032fb670>]}
2022-03-14 15:56:42.316687 (MainThread): Partial parsing not enabled
2022-03-14 15:56:42.325113 (MainThread): Parsing macros/etc.sql
2022-03-14 15:56:42.327307 (MainThread): Parsing macros/catalog.sql
2022-03-14 15:56:42.332729 (MainThread): Parsing macros/adapters.sql
2022-03-14 15:56:42.345613 (MainThread): Parsing macros/materializations/seed.sql
2022-03-14 15:56:42.347232 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 15:56:42.348927 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 15:56:42.355320 (MainThread): Parsing macros/materializations/copy.sql
2022-03-14 15:56:42.358070 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 15:56:42.366171 (MainThread): Parsing macros/materializations/snapshot.sql
2022-03-14 15:56:42.367185 (MainThread): Parsing macros/core.sql
2022-03-14 15:56:42.369565 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 15:56:42.374080 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 15:56:42.380775 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 15:56:42.381811 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 15:56:42.393320 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 15:56:42.419473 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 15:56:42.434495 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 15:56:42.435622 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 15:56:42.440704 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 15:56:42.450800 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 15:56:42.455632 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 15:56:42.459934 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 15:56:42.463113 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 15:56:42.463631 (MainThread): Parsing macros/etc/query.sql
2022-03-14 15:56:42.464215 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 15:56:42.465209 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 15:56:42.471189 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 15:56:42.472351 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 15:56:42.473300 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 15:56:42.507136 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 15:56:42.508160 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 15:56:42.508844 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 15:56:42.509632 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 15:56:42.621176 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:56:42.627212 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_test".
2022-03-14 15:56:42.629143 (MainThread): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:56:42.631065 (MainThread): Acquiring new bigquery connection "model.my_new_project.dim_customer_test".
2022-03-14 15:56:42.659772 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1c9028f9-abb6-41d1-833d-f61b28c9885e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf03dfde80>]}
2022-03-14 15:56:42.662651 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 15:56:42.663118 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1c9028f9-abb6-41d1-833d-f61b28c9885e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faee01ae3a0>]}
2022-03-14 15:56:42.663241 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 164 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 15:56:42.663999 (MainThread): 
2022-03-14 15:56:42.664160 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:56:42.664799 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev".
2022-03-14 15:56:42.664969 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 15:56:42.665591 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2022-03-14 15:56:43.743295 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_bicycle-health-dbt-dev_dbt_kris".
2022-03-14 15:56:43.744112 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 15:56:43.744653 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:56:43.951155 (MainThread): 11:56:43 | Concurrency: 8 threads (target='dev')
2022-03-14 15:56:43.951495 (MainThread): 11:56:43 | 
2022-03-14 15:56:43.954657 (MainThread): unclosed <ssl.SSLSocket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62091), raddr=('172.217.13.138', 443)>
2022-03-14 15:56:43.954903 (MainThread): unclosed <ssl.SSLSocket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62092), raddr=('172.217.13.106', 443)>
2022-03-14 15:56:43.957786 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 15:56:43.957996 (Thread-2): Began running node model.my_new_project.dim_customer_test
2022-03-14 15:56:43.958115 (Thread-3): Began running node model.my_new_project.my_test
2022-03-14 15:56:43.958340 (Thread-1): 11:56:43 | 1 of 4 START table model dbt_kris.my_first_dbt_model................. [RUN]
2022-03-14 15:56:43.958526 (Thread-2): 11:56:43 | 2 of 4 START view model dbt_kris.dim_customer_test................... [RUN]
2022-03-14 15:56:43.958695 (Thread-3): 11:56:43 | 3 of 4 START table model dbt_kris.my_test............................ [RUN]
2022-03-14 15:56:43.959190 (Thread-1): Acquiring new bigquery connection "model.my_new_project.my_first_dbt_model".
2022-03-14 15:56:43.959507 (Thread-2): Acquiring new bigquery connection "model.my_new_project.dim_customer_test".
2022-03-14 15:56:43.959899 (Thread-3): Acquiring new bigquery connection "model.my_new_project.my_test".
2022-03-14 15:56:43.960097 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 15:56:43.960225 (Thread-2): Compiling model.my_new_project.dim_customer_test
2022-03-14 15:56:43.960329 (Thread-3): Compiling model.my_new_project.my_test
2022-03-14 15:56:43.964524 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:56:43.965653 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 15:56:43.967718 (Thread-3): Writing injected SQL for node "model.my_new_project.my_test"
2022-03-14 15:56:43.968311 (Thread-2): finished collecting timing info
2022-03-14 15:56:43.968459 (Thread-1): finished collecting timing info
2022-03-14 15:56:43.968544 (Thread-3): finished collecting timing info
2022-03-14 15:56:44.005957 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 15:56:44.006859 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 15:56:44.008181 (Thread-3): Opening a new connection, currently in state init
2022-03-14 15:56:44.008340 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:56:44.008505 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2022-03-14 15:56:44.009914 (Thread-2): Opening a new connection, currently in state init
2022-03-14 15:56:44.010039 (Thread-2): On model.my_new_project.dim_customer_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer_test"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer_test`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2022-03-14 15:56:44.257051 (Thread-3): Writing runtime SQL for node "model.my_new_project.my_test"
2022-03-14 15:56:44.258104 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 15:56:44.258726 (Thread-3): On model.my_new_project.my_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_test"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_test`
  
  
  OPTIONS()
  as (
    

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
  );
    
2022-03-14 15:56:44.258893 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create or replace table `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2022-03-14 15:56:44.308636 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('The project raw has not enabled BigQuery.')
2022-03-14 15:56:45.512540 (Thread-2): finished collecting timing info
2022-03-14 15:56:45.514402 (Thread-2): Database Error in model dim_customer_test (models/example/dim_customer_test.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer_test.sql
Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    yield
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 335, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 528, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1372, in result
    do_get_result()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 286, in retry_wrapped_func
    return retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/retry.py", line 189, in retry_target
    return target()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1362, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 713, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/google/api_core/future/polling.py", line 135, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 The project raw has not enabled BigQuery.

(job ID: 3922a756-b381-4a59-8a69-58c8ac2a9170)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_customer_test"} */
   2:
   3:
   4:  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`dim_customer_test`
   5:  OPTIONS()
   6:  as with customers as (
   7:
   8:    select
   9:        id as customer_id,
  10:        first_name,
  11:        last_name
  12:
  13:    from raw.jaffle_shop.customers
  14:
  15:),
  16:
  17:orders as (
  18:
  19:    select
  20:        id as order_id,
  21:        user_id as customer_id,
  22:        order_date,
  23:        status
  24:
  25:    from raw.jaffle_shop.orders
  26:
  27:),
  28:
  29:customer_orders as (
  30:
  31:    select
  32:        customer_id,
  33:
  34:        min(order_date) as first_order_date,
  35:        max(order_date) as most_recent_order_date,
  36:        count(order_id) as number_of_orders
  37:
  38:    from orders
  39:
  40:    group by 1
  41:
  42:),
  43:
  44:
  45:final as (
  46:
  47:    select
  48:        customers.customer_id,
  49:        customers.first_name,
  50:        customers.last_name,
  51:        customer_orders.first_order_date,
  52:        customer_orders.most_recent_order_date,
  53:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  54:
  55:    from customers
  56:
  57:    left join customer_orders using (customer_id)
  58:
  59:)
  60:
  61:select * from final;
  62:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 346, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 337, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 542, in _retry_and_handle
    return retry.retry_target(
  File "/Users/kris/opt/anaconda3/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in exception_handler
    self.handle_error(e, message)
  File "/Users/kris/opt/anaconda3/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 145, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model dim_customer_test (models/example/dim_customer_test.sql)
  The project raw has not enabled BigQuery.
  compiled SQL at target/run/my_new_project/models/example/dim_customer_test.sql
2022-03-14 15:56:45.527092 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c9028f9-abb6-41d1-833d-f61b28c9885e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faee01e3400>]}
2022-03-14 15:56:45.527831 (Thread-2): 11:56:45 | 2 of 4 ERROR creating view model dbt_kris.dim_customer_test.......... [ERROR in 1.57s]
2022-03-14 15:56:45.528058 (Thread-2): Finished running node model.my_new_project.dim_customer_test
2022-03-14 15:56:45.957499 (Thread-3): finished collecting timing info
2022-03-14 15:56:45.958231 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c9028f9-abb6-41d1-833d-f61b28c9885e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faed80261c0>]}
2022-03-14 15:56:45.958768 (Thread-3): 11:56:45 | 3 of 4 OK created table model dbt_kris.my_test....................... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.00s]
2022-03-14 15:56:45.958980 (Thread-3): Finished running node model.my_new_project.my_test
2022-03-14 15:56:46.248401 (Thread-1): finished collecting timing info
2022-03-14 15:56:46.250277 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c9028f9-abb6-41d1-833d-f61b28c9885e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef0598250>]}
2022-03-14 15:56:46.251131 (Thread-1): 11:56:46 | 1 of 4 OK created table model dbt_kris.my_first_dbt_model............ [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 2.29s]
2022-03-14 15:56:46.251371 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 15:56:46.252458 (Thread-5): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 15:56:46.252976 (Thread-5): 11:56:46 | 4 of 4 START view model dbt_kris.my_second_dbt_model................. [RUN]
2022-03-14 15:56:46.253545 (Thread-5): Acquiring new bigquery connection "model.my_new_project.my_second_dbt_model".
2022-03-14 15:56:46.253714 (Thread-5): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 15:56:46.257446 (Thread-5): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:56:46.258183 (Thread-5): finished collecting timing info
2022-03-14 15:56:46.262931 (Thread-5): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 15:56:46.263511 (Thread-5): Opening a new connection, currently in state init
2022-03-14 15:56:46.263678 (Thread-5): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */


  create or replace view `bicycle-health-dbt-dev`.`dbt_kris`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `bicycle-health-dbt-dev`.`dbt_kris`.`my_first_dbt_model`
where id = 1;


2022-03-14 15:56:47.432452 (Thread-5): finished collecting timing info
2022-03-14 15:56:47.433070 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c9028f9-abb6-41d1-833d-f61b28c9885e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faee01d87f0>]}
2022-03-14 15:56:47.433553 (Thread-5): 11:56:47 | 4 of 4 OK created view model dbt_kris.my_second_dbt_model............ [OK in 1.18s]
2022-03-14 15:56:47.433747 (Thread-5): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 15:56:47.435585 (MainThread): Acquiring new bigquery connection "master".
2022-03-14 15:56:47.436127 (MainThread): 11:56:47 | 
2022-03-14 15:56:47.436320 (MainThread): 11:56:47 | Finished running 2 view models, 2 table models in 4.77s.
2022-03-14 15:56:47.436469 (MainThread): Connection 'master' was properly closed.
2022-03-14 15:56:47.436574 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 15:56:47.436672 (MainThread): Connection 'model.my_new_project.dim_customer_test' was properly closed.
2022-03-14 15:56:47.436767 (MainThread): Connection 'model.my_new_project.my_test' was properly closed.
2022-03-14 15:56:47.436858 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 15:56:47.440474 (MainThread): unclosed <ssl.SSLSocket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62095), raddr=('172.217.13.106', 443)>
2022-03-14 15:56:47.440806 (MainThread): unclosed <ssl.SSLSocket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62094), raddr=('172.217.13.106', 443)>
2022-03-14 15:56:47.441000 (MainThread): unclosed <ssl.SSLSocket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62096), raddr=('172.217.13.106', 443)>
2022-03-14 15:56:47.441185 (MainThread): unclosed <ssl.SSLSocket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.167', 62098), raddr=('172.217.13.106', 443)>
2022-03-14 15:56:47.446939 (MainThread): 
2022-03-14 15:56:47.447111 (MainThread): Completed with 1 error and 0 warnings:
2022-03-14 15:56:47.447240 (MainThread): 
2022-03-14 15:56:47.447363 (MainThread): Database Error in model dim_customer_test (models/example/dim_customer_test.sql)
2022-03-14 15:56:47.447472 (MainThread):   The project raw has not enabled BigQuery.
2022-03-14 15:56:47.447568 (MainThread):   compiled SQL at target/run/my_new_project/models/example/dim_customer_test.sql
2022-03-14 15:56:47.447682 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2022-03-14 15:56:47.447954 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef0524eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef0524e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef0524d90>]}
2022-03-14 15:56:47.448189 (MainThread): Flushing usage events
2022-03-14 16:03:14.898183 (MainThread): Running with dbt=0.20.2
2022-03-14 16:03:14.900347 (MainThread): Profile not loaded due to error: Runtime Error
  Could not find profile named 'default'
2022-03-14 16:03:14.900367 (MainThread): No profile "default" found, continuing with no target
2022-03-14 16:03:14.911221 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.deps.DepsTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='deps', single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', warn_error=False, which='deps', write_json=True)
2022-03-14 16:03:14.911780 (MainThread): Tracking: do not track
2022-03-14 16:03:14.927600 (MainThread): Warning: No packages were found in packages.yml
2022-03-14 16:03:14.928014 (MainThread): Flushing usage events
2022-03-14 17:23:31.207333 (MainThread): Running with dbt=0.20.2
2022-03-14 17:23:32.178763 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 17:23:32.648571 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 17:23:32.655812 (MainThread): Tracking: tracking
2022-03-14 17:23:32.656226 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f3aff70a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f3afe5cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f48bf8e50>]}
2022-03-14 17:23:32.664162 (MainThread): Partial parsing not enabled
2022-03-14 17:23:32.672830 (MainThread): Parsing macros/catalog.sql
2022-03-14 17:23:32.674745 (MainThread): Parsing macros/adapters.sql
2022-03-14 17:23:32.697532 (MainThread): Parsing macros/materializations/merge.sql
2022-03-14 17:23:32.698814 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 17:23:32.699663 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 17:23:32.702154 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 17:23:32.708066 (MainThread): Parsing macros/core.sql
2022-03-14 17:23:32.710495 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 17:23:32.715063 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 17:23:32.721745 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 17:23:32.722799 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 17:23:32.734557 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 17:23:32.761717 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 17:23:32.776897 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 17:23:32.778013 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 17:23:32.783147 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 17:23:32.793331 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 17:23:32.798253 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 17:23:32.802589 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 17:23:32.805707 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 17:23:32.806219 (MainThread): Parsing macros/etc/query.sql
2022-03-14 17:23:32.806783 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 17:23:32.807741 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 17:23:32.813720 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 17:23:32.814891 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 17:23:32.815841 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 17:23:32.849613 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 17:23:32.850630 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 17:23:32.851300 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 17:23:32.852083 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 17:23:32.956423 (MainThread): Acquiring new snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:23:32.962319 (MainThread): Acquiring new snowflake connection "model.my_new_project.my_test".
2022-03-14 17:23:32.964151 (MainThread): Acquiring new snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:23:32.965936 (MainThread): Acquiring new snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:23:32.992428 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake_fundamentals.example

2022-03-14 17:23:32.995690 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '00e7a771-d856-442f-9733-26fe56232067', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f581addc0>]}
2022-03-14 17:23:32.999969 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 17:23:33.000519 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '00e7a771-d856-442f-9733-26fe56232067', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f581add30>]}
2022-03-14 17:23:33.000672 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 151 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 17:23:33.001426 (MainThread): 
2022-03-14 17:23:33.001615 (MainThread): Acquiring new snowflake connection "master".
2022-03-14 17:23:33.002253 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_ANALYTICS".
2022-03-14 17:23:33.011167 (ThreadPoolExecutor-0_0): Using snowflake connection "list_ANALYTICS".
2022-03-14 17:23:33.011302 (ThreadPoolExecutor-0_0): On list_ANALYTICS: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "connection_name": "list_ANALYTICS"} */

    show terse schemas in database ANALYTICS
    limit 10000
2022-03-14 17:23:33.011353 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 17:23:34.523418 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 1.51 seconds
2022-03-14 17:23:34.532436 (ThreadPoolExecutor-0_0): On list_ANALYTICS: Close
2022-03-14 17:23:34.646414 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_ANALYTICS_PUBLIC".
2022-03-14 17:23:34.658249 (ThreadPoolExecutor-1_0): Using snowflake connection "list_ANALYTICS_PUBLIC".
2022-03-14 17:23:34.658406 (ThreadPoolExecutor-1_0): On list_ANALYTICS_PUBLIC: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "connection_name": "list_ANALYTICS_PUBLIC"} */

    show terse objects in ANALYTICS.PUBLIC
2022-03-14 17:23:34.658533 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 17:23:35.256504 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 0 in 0.60 seconds
2022-03-14 17:23:35.256926 (ThreadPoolExecutor-1_0): On list_ANALYTICS_PUBLIC: Close
2022-03-14 17:23:35.369396 (MainThread): Using snowflake connection "master".
2022-03-14 17:23:35.369586 (MainThread): On master: BEGIN
2022-03-14 17:23:35.369701 (MainThread): Opening a new connection, currently in state init
2022-03-14 17:23:35.990487 (MainThread): SQL status: SUCCESS 1 in 0.62 seconds
2022-03-14 17:23:35.991141 (MainThread): On master: COMMIT
2022-03-14 17:23:35.991550 (MainThread): Using snowflake connection "master".
2022-03-14 17:23:35.991740 (MainThread): On master: COMMIT
2022-03-14 17:23:36.196332 (MainThread): SQL status: SUCCESS 1 in 0.20 seconds
2022-03-14 17:23:36.197104 (MainThread): On master: Close
2022-03-14 17:23:36.311075 (MainThread): 13:23:36 | Concurrency: 10 threads (target='dev')
2022-03-14 17:23:36.311689 (MainThread): 13:23:36 | 
2022-03-14 17:23:36.315820 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 17:23:36.316188 (Thread-2): Began running node model.my_new_project.dim_customer_test
2022-03-14 17:23:36.316613 (Thread-1): 13:23:36 | 1 of 4 START table model PUBLIC.my_first_dbt_model................... [RUN]
2022-03-14 17:23:36.316759 (Thread-3): Began running node model.my_new_project.my_test
2022-03-14 17:23:36.317069 (Thread-2): 13:23:36 | 2 of 4 START view model PUBLIC.dim_customer_test..................... [RUN]
2022-03-14 17:23:36.317634 (Thread-1): Acquiring new snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:23:36.318051 (Thread-3): 13:23:36 | 3 of 4 START table model PUBLIC.my_test.............................. [RUN]
2022-03-14 17:23:36.318677 (Thread-2): Acquiring new snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:23:36.318881 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 17:23:36.319134 (Thread-2): Compiling model.my_new_project.dim_customer_test
2022-03-14 17:23:36.323798 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 17:23:36.324430 (Thread-3): Acquiring new snowflake connection "model.my_new_project.my_test".
2022-03-14 17:23:36.326105 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 17:23:36.326469 (Thread-3): Compiling model.my_new_project.my_test
2022-03-14 17:23:36.329800 (Thread-3): Writing injected SQL for node "model.my_new_project.my_test"
2022-03-14 17:23:36.330331 (Thread-2): finished collecting timing info
2022-03-14 17:23:36.330503 (Thread-1): finished collecting timing info
2022-03-14 17:23:36.369826 (Thread-3): finished collecting timing info
2022-03-14 17:23:36.373628 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 17:23:36.378723 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 17:23:36.379947 (Thread-3): Writing runtime SQL for node "model.my_new_project.my_test"
2022-03-14 17:23:36.380819 (Thread-1): Using snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:23:36.382170 (Thread-2): Using snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:23:36.382224 (Thread-1): On model.my_new_project.my_first_dbt_model: BEGIN
2022-03-14 17:23:36.382614 (Thread-3): Using snowflake connection "model.my_new_project.my_test".
2022-03-14 17:23:36.382676 (Thread-2): On model.my_new_project.dim_customer_test: BEGIN
2022-03-14 17:23:36.382745 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 17:23:36.382799 (Thread-3): On model.my_new_project.my_test: BEGIN
2022-03-14 17:23:36.382852 (Thread-2): Opening a new connection, currently in state init
2022-03-14 17:23:36.383089 (Thread-3): Opening a new connection, currently in state init
2022-03-14 17:23:36.944263 (Thread-3): SQL status: SUCCESS 1 in 0.56 seconds
2022-03-14 17:23:36.944648 (Thread-3): Using snowflake connection "model.my_new_project.my_test".
2022-03-14 17:23:36.944790 (Thread-3): On model.my_new_project.my_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "node_id": "model.my_new_project.my_test"} */


      create or replace transient table ANALYTICS.PUBLIC.my_test  as
      (

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
      );
2022-03-14 17:23:36.958635 (Thread-2): SQL status: SUCCESS 1 in 0.58 seconds
2022-03-14 17:23:36.958838 (Thread-2): Using snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:23:36.958962 (Thread-2): On model.my_new_project.dim_customer_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "node_id": "model.my_new_project.dim_customer_test"} */

  create or replace  view ANALYTICS.PUBLIC.dim_customer_test  as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-03-14 17:23:37.015160 (Thread-1): SQL status: SUCCESS 1 in 0.63 seconds
2022-03-14 17:23:37.015573 (Thread-1): Using snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:23:37.015699 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


      create or replace transient table ANALYTICS.PUBLIC.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2022-03-14 17:23:37.394344 (Thread-2): SQL status: SUCCESS 1 in 0.44 seconds
2022-03-14 17:23:37.398222 (Thread-2): On model.my_new_project.dim_customer_test: COMMIT
2022-03-14 17:23:37.398615 (Thread-2): Using snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:23:37.398775 (Thread-2): On model.my_new_project.dim_customer_test: COMMIT
2022-03-14 17:23:37.477058 (Thread-2): SQL status: SUCCESS 1 in 0.08 seconds
2022-03-14 17:23:37.492050 (Thread-2): finished collecting timing info
2022-03-14 17:23:37.492452 (Thread-2): On model.my_new_project.dim_customer_test: Close
2022-03-14 17:23:37.606476 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00e7a771-d856-442f-9733-26fe56232067', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f49fa1640>]}
2022-03-14 17:23:37.607242 (Thread-2): 13:23:37 | 2 of 4 OK created view model PUBLIC.dim_customer_test................ [SUCCESS 1 in 1.29s]
2022-03-14 17:23:37.607449 (Thread-2): Finished running node model.my_new_project.dim_customer_test
2022-03-14 17:23:38.470237 (Thread-3): SQL status: SUCCESS 1 in 1.53 seconds
2022-03-14 17:23:38.473282 (Thread-3): On model.my_new_project.my_test: COMMIT
2022-03-14 17:23:38.473685 (Thread-3): Using snowflake connection "model.my_new_project.my_test".
2022-03-14 17:23:38.473832 (Thread-3): On model.my_new_project.my_test: COMMIT
2022-03-14 17:23:38.500646 (Thread-1): SQL status: SUCCESS 1 in 1.48 seconds
2022-03-14 17:23:38.503063 (Thread-1): On model.my_new_project.my_first_dbt_model: COMMIT
2022-03-14 17:23:38.503416 (Thread-1): Using snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:23:38.503576 (Thread-1): On model.my_new_project.my_first_dbt_model: COMMIT
2022-03-14 17:23:38.559166 (Thread-3): SQL status: SUCCESS 1 in 0.09 seconds
2022-03-14 17:23:38.569554 (Thread-3): finished collecting timing info
2022-03-14 17:23:38.569880 (Thread-3): On model.my_new_project.my_test: Close
2022-03-14 17:23:38.582350 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2022-03-14 17:23:38.583365 (Thread-1): finished collecting timing info
2022-03-14 17:23:38.583562 (Thread-1): On model.my_new_project.my_first_dbt_model: Close
2022-03-14 17:23:38.686249 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00e7a771-d856-442f-9733-26fe56232067', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f49ecabe0>]}
2022-03-14 17:23:38.687202 (Thread-3): 13:23:38 | 3 of 4 OK created table model PUBLIC.my_test......................... [SUCCESS 1 in 2.37s]
2022-03-14 17:23:38.687447 (Thread-3): Finished running node model.my_new_project.my_test
2022-03-14 17:23:38.699111 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00e7a771-d856-442f-9733-26fe56232067', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f49f7eaf0>]}
2022-03-14 17:23:38.699758 (Thread-1): 13:23:38 | 1 of 4 OK created table model PUBLIC.my_first_dbt_model.............. [SUCCESS 1 in 2.38s]
2022-03-14 17:23:38.699974 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 17:23:38.701179 (Thread-5): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 17:23:38.701587 (Thread-5): 13:23:38 | 4 of 4 START view model PUBLIC.my_second_dbt_model................... [RUN]
2022-03-14 17:23:38.702008 (Thread-5): Acquiring new snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:23:38.702147 (Thread-5): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 17:23:38.705115 (Thread-5): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 17:23:38.705641 (Thread-5): finished collecting timing info
2022-03-14 17:23:38.708551 (Thread-5): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 17:23:38.709716 (Thread-5): Using snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:23:38.709843 (Thread-5): On model.my_new_project.my_second_dbt_model: BEGIN
2022-03-14 17:23:38.709951 (Thread-5): Opening a new connection, currently in state init
2022-03-14 17:23:39.112417 (Thread-5): SQL status: SUCCESS 1 in 0.40 seconds
2022-03-14 17:23:39.113282 (Thread-5): Using snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:23:39.113545 (Thread-5): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create or replace  view ANALYTICS.PUBLIC.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from ANALYTICS.PUBLIC.my_first_dbt_model
where id = 1
  );
2022-03-14 17:23:39.401929 (Thread-5): SQL status: SUCCESS 1 in 0.29 seconds
2022-03-14 17:23:39.403337 (Thread-5): On model.my_new_project.my_second_dbt_model: COMMIT
2022-03-14 17:23:39.403560 (Thread-5): Using snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:23:39.403667 (Thread-5): On model.my_new_project.my_second_dbt_model: COMMIT
2022-03-14 17:23:39.472790 (Thread-5): SQL status: SUCCESS 1 in 0.07 seconds
2022-03-14 17:23:39.479401 (Thread-5): finished collecting timing info
2022-03-14 17:23:39.479814 (Thread-5): On model.my_new_project.my_second_dbt_model: Close
2022-03-14 17:23:39.589211 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00e7a771-d856-442f-9733-26fe56232067', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f3b12faf0>]}
2022-03-14 17:23:39.589862 (Thread-5): 13:23:39 | 4 of 4 OK created view model PUBLIC.my_second_dbt_model.............. [SUCCESS 1 in 0.89s]
2022-03-14 17:23:39.590085 (Thread-5): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 17:23:39.591985 (MainThread): Acquiring new snowflake connection "master".
2022-03-14 17:23:39.592328 (MainThread): Using snowflake connection "master".
2022-03-14 17:23:39.592465 (MainThread): On master: BEGIN
2022-03-14 17:23:39.592593 (MainThread): Opening a new connection, currently in state closed
2022-03-14 17:23:40.015799 (MainThread): SQL status: SUCCESS 1 in 0.42 seconds
2022-03-14 17:23:40.016563 (MainThread): On master: COMMIT
2022-03-14 17:23:40.016992 (MainThread): Using snowflake connection "master".
2022-03-14 17:23:40.017179 (MainThread): On master: COMMIT
2022-03-14 17:23:40.198946 (MainThread): SQL status: SUCCESS 1 in 0.18 seconds
2022-03-14 17:23:40.199706 (MainThread): On master: Close
2022-03-14 17:23:40.306473 (MainThread): 13:23:40 | 
2022-03-14 17:23:40.306682 (MainThread): 13:23:40 | Finished running 2 view models, 2 table models in 7.30s.
2022-03-14 17:23:40.306792 (MainThread): Connection 'master' was properly closed.
2022-03-14 17:23:40.306862 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 17:23:40.306924 (MainThread): Connection 'model.my_new_project.dim_customer_test' was properly closed.
2022-03-14 17:23:40.306985 (MainThread): Connection 'model.my_new_project.my_test' was properly closed.
2022-03-14 17:23:40.307042 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 17:23:40.311616 (MainThread): 
2022-03-14 17:23:40.311778 (MainThread): Completed successfully
2022-03-14 17:23:40.311875 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-03-14 17:23:40.312044 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f581adc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f581ade50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7f581db310>]}
2022-03-14 17:23:40.312252 (MainThread): Flushing usage events
2022-03-14 17:30:29.681792 (MainThread): Running with dbt=0.20.2
2022-03-14 17:30:30.852390 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 17:30:31.350959 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 17:30:31.354266 (MainThread): Tracking: tracking
2022-03-14 17:30:31.354558 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe12298040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe12286d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe20d18e50>]}
2022-03-14 17:30:31.362303 (MainThread): Partial parsing not enabled
2022-03-14 17:30:31.370431 (MainThread): Parsing macros/catalog.sql
2022-03-14 17:30:31.372301 (MainThread): Parsing macros/adapters.sql
2022-03-14 17:30:31.394259 (MainThread): Parsing macros/materializations/merge.sql
2022-03-14 17:30:31.395518 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 17:30:31.396357 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 17:30:31.398826 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 17:30:31.404666 (MainThread): Parsing macros/core.sql
2022-03-14 17:30:31.407073 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 17:30:31.411569 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 17:30:31.418117 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 17:30:31.419156 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 17:30:31.430764 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 17:30:31.456653 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 17:30:31.471446 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 17:30:31.472550 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 17:30:31.477619 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 17:30:31.487537 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 17:30:31.492332 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 17:30:31.496597 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 17:30:31.499700 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 17:30:31.500207 (MainThread): Parsing macros/etc/query.sql
2022-03-14 17:30:31.500773 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 17:30:31.501727 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 17:30:31.507608 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 17:30:31.508778 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 17:30:31.509732 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 17:30:31.542727 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 17:30:31.543789 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 17:30:31.544465 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 17:30:31.545244 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 17:30:31.652417 (MainThread): Acquiring new snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:30:31.658423 (MainThread): Acquiring new snowflake connection "model.my_new_project.my_test".
2022-03-14 17:30:31.660271 (MainThread): Acquiring new snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:30:31.662087 (MainThread): Acquiring new snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:31.687269 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake_fundamentals.example

2022-03-14 17:30:31.690408 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1afa0f6e-40c4-487b-8c97-fe9923f1284c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe00043df0>]}
2022-03-14 17:30:31.693811 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 17:30:31.694370 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1afa0f6e-40c4-487b-8c97-fe9923f1284c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe00043d60>]}
2022-03-14 17:30:31.694536 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 151 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 17:30:31.695453 (MainThread): 
2022-03-14 17:30:31.695642 (MainThread): Acquiring new snowflake connection "master".
2022-03-14 17:30:31.696236 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_ANALYTICS".
2022-03-14 17:30:31.704358 (ThreadPoolExecutor-0_0): Using snowflake connection "list_ANALYTICS".
2022-03-14 17:30:31.704418 (ThreadPoolExecutor-0_0): On list_ANALYTICS: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "connection_name": "list_ANALYTICS"} */

    show terse schemas in database ANALYTICS
    limit 10000
2022-03-14 17:30:31.704464 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 17:30:32.419425 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 0.71 seconds
2022-03-14 17:30:32.427623 (ThreadPoolExecutor-0_0): On list_ANALYTICS: Close
2022-03-14 17:30:32.534423 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_ANALYTICS_PUBLIC".
2022-03-14 17:30:32.544440 (ThreadPoolExecutor-1_0): Using snowflake connection "list_ANALYTICS_PUBLIC".
2022-03-14 17:30:32.544638 (ThreadPoolExecutor-1_0): On list_ANALYTICS_PUBLIC: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "connection_name": "list_ANALYTICS_PUBLIC"} */

    show terse objects in ANALYTICS.PUBLIC
2022-03-14 17:30:32.544757 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 17:30:33.128592 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.58 seconds
2022-03-14 17:30:33.129775 (ThreadPoolExecutor-1_0): On list_ANALYTICS_PUBLIC: Close
2022-03-14 17:30:33.256511 (MainThread): Using snowflake connection "master".
2022-03-14 17:30:33.256828 (MainThread): On master: BEGIN
2022-03-14 17:30:33.257011 (MainThread): Opening a new connection, currently in state init
2022-03-14 17:30:33.861624 (MainThread): SQL status: SUCCESS 1 in 0.60 seconds
2022-03-14 17:30:33.862539 (MainThread): On master: COMMIT
2022-03-14 17:30:33.862884 (MainThread): Using snowflake connection "master".
2022-03-14 17:30:33.863022 (MainThread): On master: COMMIT
2022-03-14 17:30:34.025871 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2022-03-14 17:30:34.026117 (MainThread): On master: Close
2022-03-14 17:30:34.142099 (MainThread): 13:30:34 | Concurrency: 10 threads (target='dev')
2022-03-14 17:30:34.142463 (MainThread): 13:30:34 | 
2022-03-14 17:30:34.146766 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2022-03-14 17:30:34.147072 (Thread-2): Began running node model.my_new_project.dim_customer_test
2022-03-14 17:30:34.147276 (Thread-3): Began running node model.my_new_project.my_test
2022-03-14 17:30:34.147650 (Thread-1): 13:30:34 | 1 of 4 START table model PUBLIC.my_first_dbt_model................... [RUN]
2022-03-14 17:30:34.148004 (Thread-2): 13:30:34 | 2 of 4 START view model PUBLIC.dim_customer_test..................... [RUN]
2022-03-14 17:30:34.148283 (Thread-3): 13:30:34 | 3 of 4 START table model PUBLIC.my_test.............................. [RUN]
2022-03-14 17:30:34.148821 (Thread-1): Acquiring new snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:30:34.149184 (Thread-2): Acquiring new snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:34.149662 (Thread-3): Acquiring new snowflake connection "model.my_new_project.my_test".
2022-03-14 17:30:34.150292 (Thread-2): Compiling model.my_new_project.dim_customer_test
2022-03-14 17:30:34.150504 (Thread-3): Compiling model.my_new_project.my_test
2022-03-14 17:30:34.150730 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2022-03-14 17:30:34.152781 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 17:30:34.156262 (Thread-3): Writing injected SQL for node "model.my_new_project.my_test"
2022-03-14 17:30:34.159007 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 17:30:34.160644 (Thread-2): finished collecting timing info
2022-03-14 17:30:34.160842 (Thread-1): finished collecting timing info
2022-03-14 17:30:34.168631 (Thread-3): finished collecting timing info
2022-03-14 17:30:34.199043 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 17:30:34.210002 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2022-03-14 17:30:34.211172 (Thread-3): Writing runtime SQL for node "model.my_new_project.my_test"
2022-03-14 17:30:34.212096 (Thread-1): Using snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:30:34.213444 (Thread-2): Using snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:34.213497 (Thread-1): On model.my_new_project.my_first_dbt_model: BEGIN
2022-03-14 17:30:34.213968 (Thread-3): Using snowflake connection "model.my_new_project.my_test".
2022-03-14 17:30:34.214031 (Thread-2): On model.my_new_project.dim_customer_test: BEGIN
2022-03-14 17:30:34.214090 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 17:30:34.214137 (Thread-3): On model.my_new_project.my_test: BEGIN
2022-03-14 17:30:34.214185 (Thread-2): Opening a new connection, currently in state init
2022-03-14 17:30:34.214740 (Thread-3): Opening a new connection, currently in state init
2022-03-14 17:30:34.774726 (Thread-2): SQL status: SUCCESS 1 in 0.56 seconds
2022-03-14 17:30:34.775030 (Thread-2): Using snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:34.775160 (Thread-2): On model.my_new_project.dim_customer_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "node_id": "model.my_new_project.dim_customer_test"} */

  create or replace  view ANALYTICS.PUBLIC.dim_customer_test  as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-03-14 17:30:34.812491 (Thread-3): SQL status: SUCCESS 1 in 0.60 seconds
2022-03-14 17:30:34.812902 (Thread-3): Using snowflake connection "model.my_new_project.my_test".
2022-03-14 17:30:34.813076 (Thread-3): On model.my_new_project.my_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "node_id": "model.my_new_project.my_test"} */


      create or replace transient table ANALYTICS.PUBLIC.my_test  as
      (

with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data
      );
2022-03-14 17:30:34.837850 (Thread-1): SQL status: SUCCESS 1 in 0.62 seconds
2022-03-14 17:30:34.838405 (Thread-1): Using snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:30:34.838640 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


      create or replace transient table ANALYTICS.PUBLIC.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
2022-03-14 17:30:35.136808 (Thread-2): SQL status: SUCCESS 1 in 0.36 seconds
2022-03-14 17:30:35.141647 (Thread-2): On model.my_new_project.dim_customer_test: COMMIT
2022-03-14 17:30:35.142081 (Thread-2): Using snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:35.142263 (Thread-2): On model.my_new_project.dim_customer_test: COMMIT
2022-03-14 17:30:35.212889 (Thread-2): SQL status: SUCCESS 1 in 0.07 seconds
2022-03-14 17:30:35.229228 (Thread-2): finished collecting timing info
2022-03-14 17:30:35.229521 (Thread-2): On model.my_new_project.dim_customer_test: Close
2022-03-14 17:30:35.347134 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1afa0f6e-40c4-487b-8c97-fe9923f1284c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe229056d0>]}
2022-03-14 17:30:35.348141 (Thread-2): 13:30:35 | 2 of 4 OK created view model PUBLIC.dim_customer_test................ [SUCCESS 1 in 1.20s]
2022-03-14 17:30:35.348377 (Thread-2): Finished running node model.my_new_project.dim_customer_test
2022-03-14 17:30:35.734632 (Thread-1): SQL status: SUCCESS 1 in 0.90 seconds
2022-03-14 17:30:35.738889 (Thread-1): On model.my_new_project.my_first_dbt_model: COMMIT
2022-03-14 17:30:35.739196 (Thread-1): Using snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:30:35.739314 (Thread-1): On model.my_new_project.my_first_dbt_model: COMMIT
2022-03-14 17:30:35.826322 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2022-03-14 17:30:35.839579 (Thread-1): finished collecting timing info
2022-03-14 17:30:35.839904 (Thread-1): On model.my_new_project.my_first_dbt_model: Close
2022-03-14 17:30:35.974149 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1afa0f6e-40c4-487b-8c97-fe9923f1284c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe228ffaf0>]}
2022-03-14 17:30:35.975067 (Thread-1): 13:30:35 | 1 of 4 OK created table model PUBLIC.my_first_dbt_model.............. [SUCCESS 1 in 1.83s]
2022-03-14 17:30:35.975371 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2022-03-14 17:30:35.976364 (Thread-5): Began running node model.my_new_project.my_second_dbt_model
2022-03-14 17:30:35.976901 (Thread-5): 13:30:35 | 4 of 4 START view model PUBLIC.my_second_dbt_model................... [RUN]
2022-03-14 17:30:35.977590 (Thread-5): Acquiring new snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:30:35.977802 (Thread-5): Compiling model.my_new_project.my_second_dbt_model
2022-03-14 17:30:35.981633 (Thread-5): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 17:30:35.982378 (Thread-5): finished collecting timing info
2022-03-14 17:30:35.985794 (Thread-5): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2022-03-14 17:30:35.987115 (Thread-5): Using snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:30:35.987264 (Thread-5): On model.my_new_project.my_second_dbt_model: BEGIN
2022-03-14 17:30:35.987389 (Thread-5): Opening a new connection, currently in state init
2022-03-14 17:30:36.243377 (Thread-3): SQL status: SUCCESS 1 in 1.43 seconds
2022-03-14 17:30:36.244217 (Thread-3): On model.my_new_project.my_test: COMMIT
2022-03-14 17:30:36.244337 (Thread-3): Using snowflake connection "model.my_new_project.my_test".
2022-03-14 17:30:36.244395 (Thread-3): On model.my_new_project.my_test: COMMIT
2022-03-14 17:30:36.320279 (Thread-3): SQL status: SUCCESS 1 in 0.08 seconds
2022-03-14 17:30:36.321173 (Thread-3): finished collecting timing info
2022-03-14 17:30:36.321349 (Thread-3): On model.my_new_project.my_test: Close
2022-03-14 17:30:36.388630 (Thread-5): SQL status: SUCCESS 1 in 0.40 seconds
2022-03-14 17:30:36.388970 (Thread-5): Using snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:30:36.389113 (Thread-5): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create or replace  view ANALYTICS.PUBLIC.my_second_dbt_model  as (
    -- Use the `ref` function to select from other models

select *
from ANALYTICS.PUBLIC.my_first_dbt_model
where id = 1
  );
2022-03-14 17:30:36.426839 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1afa0f6e-40c4-487b-8c97-fe9923f1284c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe22905e20>]}
2022-03-14 17:30:36.427639 (Thread-3): 13:30:36 | 3 of 4 OK created table model PUBLIC.my_test......................... [SUCCESS 1 in 2.28s]
2022-03-14 17:30:36.427905 (Thread-3): Finished running node model.my_new_project.my_test
2022-03-14 17:30:36.672279 (Thread-5): SQL status: SUCCESS 1 in 0.28 seconds
2022-03-14 17:30:36.675417 (Thread-5): On model.my_new_project.my_second_dbt_model: COMMIT
2022-03-14 17:30:36.675831 (Thread-5): Using snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:30:36.675970 (Thread-5): On model.my_new_project.my_second_dbt_model: COMMIT
2022-03-14 17:30:36.751971 (Thread-5): SQL status: SUCCESS 1 in 0.08 seconds
2022-03-14 17:30:36.753719 (Thread-5): finished collecting timing info
2022-03-14 17:30:36.754030 (Thread-5): On model.my_new_project.my_second_dbt_model: Close
2022-03-14 17:30:36.878291 (Thread-5): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1afa0f6e-40c4-487b-8c97-fe9923f1284c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe22905160>]}
2022-03-14 17:30:36.879563 (Thread-5): 13:30:36 | 4 of 4 OK created view model PUBLIC.my_second_dbt_model.............. [SUCCESS 1 in 0.90s]
2022-03-14 17:30:36.879902 (Thread-5): Finished running node model.my_new_project.my_second_dbt_model
2022-03-14 17:30:36.882061 (MainThread): Acquiring new snowflake connection "master".
2022-03-14 17:30:36.882409 (MainThread): Using snowflake connection "master".
2022-03-14 17:30:36.882541 (MainThread): On master: BEGIN
2022-03-14 17:30:36.882670 (MainThread): Opening a new connection, currently in state closed
2022-03-14 17:30:37.325778 (MainThread): SQL status: SUCCESS 1 in 0.44 seconds
2022-03-14 17:30:37.326509 (MainThread): On master: COMMIT
2022-03-14 17:30:37.327033 (MainThread): Using snowflake connection "master".
2022-03-14 17:30:37.327314 (MainThread): On master: COMMIT
2022-03-14 17:30:37.657052 (MainThread): SQL status: SUCCESS 1 in 0.33 seconds
2022-03-14 17:30:37.657832 (MainThread): On master: Close
2022-03-14 17:30:37.779703 (MainThread): 13:30:37 | 
2022-03-14 17:30:37.780272 (MainThread): 13:30:37 | Finished running 2 view models, 2 table models in 6.08s.
2022-03-14 17:30:37.780503 (MainThread): Connection 'master' was properly closed.
2022-03-14 17:30:37.780642 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2022-03-14 17:30:37.780766 (MainThread): Connection 'model.my_new_project.dim_customer_test' was properly closed.
2022-03-14 17:30:37.780888 (MainThread): Connection 'model.my_new_project.my_test' was properly closed.
2022-03-14 17:30:37.781005 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2022-03-14 17:30:37.788995 (MainThread): 
2022-03-14 17:30:37.789269 (MainThread): Completed successfully
2022-03-14 17:30:37.789442 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-03-14 17:30:37.789795 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe213d3ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe10aea9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2285d190>]}
2022-03-14 17:30:37.790218 (MainThread): Flushing usage events
2022-03-14 17:30:49.826785 (MainThread): Running with dbt=0.20.2
2022-03-14 17:30:50.736379 (MainThread): NumExpr defaulting to 8 threads.
2022-03-14 17:30:51.069326 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['dim_customer_test'], partial_parse=None, profile=None, profiles_dir='/Users/kris/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, use_experimental_parser=False, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2022-03-14 17:30:51.072631 (MainThread): Tracking: tracking
2022-03-14 17:30:51.072926 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d3c26040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d3c14d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d0bf8e80>]}
2022-03-14 17:30:51.080688 (MainThread): Partial parsing not enabled
2022-03-14 17:30:51.087200 (MainThread): Parsing macros/catalog.sql
2022-03-14 17:30:51.089232 (MainThread): Parsing macros/adapters.sql
2022-03-14 17:30:51.111214 (MainThread): Parsing macros/materializations/merge.sql
2022-03-14 17:30:51.112475 (MainThread): Parsing macros/materializations/view.sql
2022-03-14 17:30:51.113304 (MainThread): Parsing macros/materializations/table.sql
2022-03-14 17:30:51.115742 (MainThread): Parsing macros/materializations/incremental.sql
2022-03-14 17:30:51.121505 (MainThread): Parsing macros/core.sql
2022-03-14 17:30:51.123873 (MainThread): Parsing macros/materializations/test.sql
2022-03-14 17:30:51.128329 (MainThread): Parsing macros/materializations/helpers.sql
2022-03-14 17:30:51.134780 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-03-14 17:30:51.135807 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-03-14 17:30:51.147290 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-03-14 17:30:51.173041 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-03-14 17:30:51.187695 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-03-14 17:30:51.188784 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-03-14 17:30:51.193785 (MainThread): Parsing macros/materializations/common/merge.sql
2022-03-14 17:30:51.203586 (MainThread): Parsing macros/materializations/table/table.sql
2022-03-14 17:30:51.208332 (MainThread): Parsing macros/materializations/view/view.sql
2022-03-14 17:30:51.212544 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-03-14 17:30:51.215602 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-03-14 17:30:51.216102 (MainThread): Parsing macros/etc/query.sql
2022-03-14 17:30:51.216660 (MainThread): Parsing macros/etc/is_incremental.sql
2022-03-14 17:30:51.217596 (MainThread): Parsing macros/etc/datetime.sql
2022-03-14 17:30:51.223385 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-03-14 17:30:51.224538 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-03-14 17:30:51.225463 (MainThread): Parsing macros/adapters/common.sql
2022-03-14 17:30:51.257862 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-03-14 17:30:51.258861 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-03-14 17:30:51.259537 (MainThread): Parsing macros/schema_tests/unique.sql
2022-03-14 17:30:51.260312 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-03-14 17:30:51.363522 (MainThread): Acquiring new snowflake connection "model.my_new_project.my_first_dbt_model".
2022-03-14 17:30:51.369339 (MainThread): Acquiring new snowflake connection "model.my_new_project.my_test".
2022-03-14 17:30:51.371140 (MainThread): Acquiring new snowflake connection "model.my_new_project.my_second_dbt_model".
2022-03-14 17:30:51.372917 (MainThread): Acquiring new snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:51.397524 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.snowflake_fundamentals.example

2022-03-14 17:30:51.400684 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f176e8ef-4a00-4483-83af-2369f94ab9fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1c11c2d60>]}
2022-03-14 17:30:51.404171 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-03-14 17:30:51.404683 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f176e8ef-4a00-4483-83af-2369f94ab9fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1c11c2cd0>]}
2022-03-14 17:30:51.404860 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 151 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2022-03-14 17:30:51.405524 (MainThread): 
2022-03-14 17:30:51.405715 (MainThread): Acquiring new snowflake connection "master".
2022-03-14 17:30:51.406264 (ThreadPoolExecutor-0_0): Acquiring new snowflake connection "list_ANALYTICS".
2022-03-14 17:30:51.414920 (ThreadPoolExecutor-0_0): Using snowflake connection "list_ANALYTICS".
2022-03-14 17:30:51.415032 (ThreadPoolExecutor-0_0): On list_ANALYTICS: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "connection_name": "list_ANALYTICS"} */

    show terse schemas in database ANALYTICS
    limit 10000
2022-03-14 17:30:51.415082 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-03-14 17:30:52.068087 (ThreadPoolExecutor-0_0): SQL status: SUCCESS 2 in 0.65 seconds
2022-03-14 17:30:52.077291 (ThreadPoolExecutor-0_0): On list_ANALYTICS: Close
2022-03-14 17:30:52.194282 (ThreadPoolExecutor-1_0): Acquiring new snowflake connection "list_ANALYTICS_PUBLIC".
2022-03-14 17:30:52.206144 (ThreadPoolExecutor-1_0): Using snowflake connection "list_ANALYTICS_PUBLIC".
2022-03-14 17:30:52.206300 (ThreadPoolExecutor-1_0): On list_ANALYTICS_PUBLIC: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "connection_name": "list_ANALYTICS_PUBLIC"} */

    show terse objects in ANALYTICS.PUBLIC
2022-03-14 17:30:52.206420 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-03-14 17:30:52.808479 (ThreadPoolExecutor-1_0): SQL status: SUCCESS 4 in 0.60 seconds
2022-03-14 17:30:52.809987 (ThreadPoolExecutor-1_0): On list_ANALYTICS_PUBLIC: Close
2022-03-14 17:30:52.944360 (MainThread): Using snowflake connection "master".
2022-03-14 17:30:52.944713 (MainThread): On master: BEGIN
2022-03-14 17:30:52.944905 (MainThread): Opening a new connection, currently in state init
2022-03-14 17:30:53.569249 (MainThread): SQL status: SUCCESS 1 in 0.62 seconds
2022-03-14 17:30:53.570168 (MainThread): On master: COMMIT
2022-03-14 17:30:53.570719 (MainThread): Using snowflake connection "master".
2022-03-14 17:30:53.570983 (MainThread): On master: COMMIT
2022-03-14 17:30:53.741680 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2022-03-14 17:30:53.742620 (MainThread): On master: Close
2022-03-14 17:30:53.854439 (MainThread): 13:30:53 | Concurrency: 10 threads (target='dev')
2022-03-14 17:30:53.854872 (MainThread): 13:30:53 | 
2022-03-14 17:30:53.858896 (Thread-1): Began running node model.my_new_project.dim_customer_test
2022-03-14 17:30:53.859419 (Thread-1): 13:30:53 | 1 of 1 START view model PUBLIC.dim_customer_test..................... [RUN]
2022-03-14 17:30:53.859951 (Thread-1): Acquiring new snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:53.860132 (Thread-1): Compiling model.my_new_project.dim_customer_test
2022-03-14 17:30:53.862856 (Thread-1): Writing injected SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 17:30:53.863621 (Thread-1): finished collecting timing info
2022-03-14 17:30:53.898200 (Thread-1): Writing runtime SQL for node "model.my_new_project.dim_customer_test"
2022-03-14 17:30:53.900494 (Thread-1): Using snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:53.900584 (Thread-1): On model.my_new_project.dim_customer_test: BEGIN
2022-03-14 17:30:53.900660 (Thread-1): Opening a new connection, currently in state closed
2022-03-14 17:30:54.311775 (Thread-1): SQL status: SUCCESS 1 in 0.41 seconds
2022-03-14 17:30:54.312674 (Thread-1): Using snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:54.312947 (Thread-1): On model.my_new_project.dim_customer_test: /* {"app": "dbt", "dbt_version": "0.20.2", "profile_name": "snowflake_fundamentals", "target_name": "dev", "node_id": "model.my_new_project.dim_customer_test"} */

  create or replace  view ANALYTICS.PUBLIC.dim_customer_test  as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from raw.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from raw.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
2022-03-14 17:30:54.682309 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2022-03-14 17:30:54.686134 (Thread-1): On model.my_new_project.dim_customer_test: COMMIT
2022-03-14 17:30:54.686632 (Thread-1): Using snowflake connection "model.my_new_project.dim_customer_test".
2022-03-14 17:30:54.686812 (Thread-1): On model.my_new_project.dim_customer_test: COMMIT
2022-03-14 17:30:54.758539 (Thread-1): SQL status: SUCCESS 1 in 0.07 seconds
2022-03-14 17:30:54.774996 (Thread-1): finished collecting timing info
2022-03-14 17:30:54.775273 (Thread-1): On model.my_new_project.dim_customer_test: Close
2022-03-14 17:30:54.899210 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f176e8ef-4a00-4483-83af-2369f94ab9fa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d3e10a90>]}
2022-03-14 17:30:54.900003 (Thread-1): 13:30:54 | 1 of 1 OK created view model PUBLIC.dim_customer_test................ [SUCCESS 1 in 1.04s]
2022-03-14 17:30:54.900280 (Thread-1): Finished running node model.my_new_project.dim_customer_test
2022-03-14 17:30:54.903718 (MainThread): Acquiring new snowflake connection "master".
2022-03-14 17:30:54.904094 (MainThread): Using snowflake connection "master".
2022-03-14 17:30:54.904236 (MainThread): On master: BEGIN
2022-03-14 17:30:54.904376 (MainThread): Opening a new connection, currently in state closed
2022-03-14 17:30:55.341483 (MainThread): SQL status: SUCCESS 1 in 0.44 seconds
2022-03-14 17:30:55.342385 (MainThread): On master: COMMIT
2022-03-14 17:30:55.342794 (MainThread): Using snowflake connection "master".
2022-03-14 17:30:55.343005 (MainThread): On master: COMMIT
2022-03-14 17:30:55.521404 (MainThread): SQL status: SUCCESS 1 in 0.18 seconds
2022-03-14 17:30:55.522204 (MainThread): On master: Close
2022-03-14 17:30:55.647207 (MainThread): 13:30:55 | 
2022-03-14 17:30:55.647718 (MainThread): 13:30:55 | Finished running 1 view model in 4.24s.
2022-03-14 17:30:55.647891 (MainThread): Connection 'master' was properly closed.
2022-03-14 17:30:55.648015 (MainThread): Connection 'model.my_new_project.dim_customer_test' was properly closed.
2022-03-14 17:30:55.656501 (MainThread): 
2022-03-14 17:30:55.656764 (MainThread): Completed successfully
2022-03-14 17:30:55.656941 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2022-03-14 17:30:55.657214 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1c1193e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1c11461f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1d3cf8580>]}
2022-03-14 17:30:55.657524 (MainThread): Flushing usage events
